{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374165d6",
   "metadata": {},
   "source": [
    "# This Expermental take CNN-adrian with LSTM model\n",
    ">CNN Learn feature of ECG morphology\n",
    ">LSTM deccide the AFIB, NORM, AFLAT, OTHER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5d47c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "c:\\Users\\arjan\\Documents\\GitHub\\SEARCH_AF_detection_OsloMet_BachelorGroup\\venv\\Lib\\site-packages\\torch\\__init__.py\n",
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Dataset loader & preparation\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import random\n",
    "from collections import Counter\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "dff = pd.read_csv(\"../../../data/ptbxl_database.csv\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "print(torch.__file__)\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e02d1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LABELS = {\"NORM\", \"AFIB\", \"AFLT\"}\n",
    "\n",
    "\n",
    "norm_ids  = []\n",
    "afib_ids  = []\n",
    "aflt_ids  = []\n",
    "other_ids = []\n",
    "\n",
    "\n",
    "LABEL_MAP = {\n",
    "    \"NORM\": 0,\n",
    "    \"AFIB\": 1,\n",
    "    \"AFLT\": 2,\n",
    "    \"OTHER\": 3\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ade0d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_repeated_label(label_sets):\n",
    "    # label_sets = list of sets, one per ECG\n",
    "    all_labels = []\n",
    "    for s in label_sets:\n",
    "        all_labels.extend(list(s))\n",
    "\n",
    "    counts = Counter(all_labels)\n",
    "\n",
    "    # label appears in 2 or more recordings\n",
    "    return any(v >= 2 for v in counts.values())\n",
    "\n",
    "\n",
    "\n",
    "def extract_labels(scp_codes):\n",
    "    codes = ast.literal_eval(scp_codes)\n",
    "    return set(codes.keys()) & TARGET_LABELS\n",
    "\n",
    "def select_from_pool(pool, label, n, seed=42):\n",
    "    \"\"\"\n",
    "    Select n ECG IDs from pool[label] and REMOVE them.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    available = list(pool[label])\n",
    "\n",
    "    if len(available) < n:\n",
    "        raise ValueError(\n",
    "            f\"Not enough ECGs for label {label}. \"\n",
    "            f\"Requested {n}, available {len(available)}\"\n",
    "        )\n",
    "\n",
    "    selected = random.sample(available, n)\n",
    "\n",
    "    # remove selected from pool\n",
    "    pool[label] -= set(selected)\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6724fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FASTER for loading ECG files\n",
    "def build_ecg_index(root=\"../../../data/records500\", suffix=\"_hr\"):\n",
    "    index = {}\n",
    "    for p in Path(root).rglob(f\"*{suffix}.hea\"):\n",
    "        ecg_id = int(p.stem.replace(suffix, \"\"))\n",
    "        index[ecg_id] = str(p.with_suffix(\"\"))\n",
    "    return index\n",
    "\n",
    "ECG_INDEX = build_ecg_index()\n",
    "\n",
    "def load_ecg_fast(ecg_id):\n",
    "    record = wfdb.rdrecord(ECG_INDEX[ecg_id])\n",
    "    return record.p_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "790c4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arrays(id_label_list):\n",
    "    X, y = [], []\n",
    "    for ecg_id, label in id_label_list:\n",
    "        X.append(load_ecg_fast(ecg_id))\n",
    "        y.append(label)\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f3d881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ECG records: 21837\n",
      "Total patients: 18885\n",
      "Patients with multiple recordings: 2127\n",
      "Max recordings for one patient: 10\n",
      "Patients with multiple labels: 269\n",
      "Percentage: 1.4%\n"
     ]
    }
   ],
   "source": [
    "#Ensure if patient_id have different ECG records, all records are in the same set\n",
    "ecg_records = dff[\"ecg_id\"].count() \n",
    "print(\"Total ECG records:\", ecg_records)\n",
    "patient_ids = dff[\"patient_id\"].value_counts()\n",
    "multiple_recordings = patient_ids[patient_ids > 1]\n",
    "print(\"Total patients:\", dff[\"patient_id\"].nunique())\n",
    "print(\"Patients with multiple recordings:\", len(multiple_recordings))\n",
    "print(\"Max recordings for one patient:\", multiple_recordings.max())\n",
    "\n",
    "def get_label(scp_codes):\n",
    "    if \"AFIB\" in scp_codes:\n",
    "        return 1\n",
    "    if \"NORM\" in scp_codes:\n",
    "        return 0\n",
    "    if \"AFLT\" in scp_codes:\n",
    "        return 2\n",
    "    \n",
    "    if \"NDT\" in scp_codes:\n",
    "        return 4\n",
    "    if \"NST_\" in scp_codes:\n",
    "        return 5\n",
    "    if \"SVARR\" in scp_codes:\n",
    "        return 6\n",
    "    if \"SVTAC\" in scp_codes:\n",
    "        return 7\n",
    "    if \"PAC\" in scp_codes:\n",
    "        return 8\n",
    "    return None\n",
    "\n",
    "dff[\"label\"] = dff[\"scp_codes\"].apply(lambda x: get_label(ast.literal_eval(x)))\n",
    "label_counts_per_patient = dff.groupby(\"patient_id\")[\"label\"].nunique()\n",
    "patients_with_label_change = label_counts_per_patient[label_counts_per_patient > 1]\n",
    "\n",
    "print(\"Patients with multiple labels:\", len(patients_with_label_change))\n",
    "print(\n",
    "    \"Percentage:\",\n",
    "    f\"{round(100 * len(patients_with_label_change) / dff['patient_id'].nunique(), 1)}%\"\n",
    ")\n",
    "\n",
    "\n",
    "dff[\"target_labels\"] = dff[\"scp_codes\"].apply(extract_labels)\n",
    "dff_target = dff[dff[\"target_labels\"].apply(len) > 0]\n",
    "\n",
    "\n",
    "patient_groups = dff_target.groupby(\"patient_id\")[\"target_labels\"]\n",
    "\n",
    "\n",
    "patients_with_repeated_label = patient_groups.apply(has_repeated_label)\n",
    "# patients with more than one ECG\n",
    "patient_target_counts = dff_target[\"patient_id\"].value_counts()\n",
    "\n",
    "patients_with_multiple_target_ecgs = patient_target_counts[\n",
    "    patient_target_counts > 1\n",
    "].index\n",
    "dff_final = dff_target[\n",
    "    dff_target[\"patient_id\"].isin(patients_with_multiple_target_ecgs)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf62d6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORM : 8329\n",
      "AFIB : 1027\n",
      "AFLT : 32\n",
      "OTHER: 2394\n",
      "TOTAL: 11782\n"
     ]
    }
   ],
   "source": [
    "dataset_root = \"../../../data/\"\n",
    "df = pd.read_csv(os.path.join(dataset_root, \"ptbxl_database.csv\"))\n",
    "for _, row in df.iterrows():\n",
    "    \n",
    "    scp_codes = ast.literal_eval(row[\"scp_codes\"])\n",
    "    label = get_label(scp_codes)\n",
    "    ecg_id = row[\"ecg_id\"]\n",
    "    p_id = row[\"patient_id\"]\n",
    "    if p_id  in dff_final[\"patient_id\"].values:\n",
    "        continue\n",
    "\n",
    "    if label is None:\n",
    "        continue\n",
    "\n",
    "\n",
    "    if label == 0:\n",
    "        norm_ids.append(ecg_id)\n",
    "\n",
    "    elif label == 1:\n",
    "        afib_ids.append(ecg_id)\n",
    "\n",
    "    elif label == 2:\n",
    "        aflt_ids.append(ecg_id)\n",
    "\n",
    "    else:\n",
    "        other_ids.append(ecg_id)\n",
    "print(\"NORM :\", len(norm_ids))\n",
    "print(\"AFIB :\", len(afib_ids))\n",
    "print(\"AFLT :\", len(aflt_ids))\n",
    "print(\"OTHER:\", len(other_ids))\n",
    "print(\"TOTAL:\", len(norm_ids) + len(afib_ids) + len(aflt_ids) + len(other_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f79aaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Learns ECG morphology:\n",
    "    QRS complex shape, amplitude, local waveform patterns\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(12, 32, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, time, leads)\n",
    "        x = x.permute(0, 2, 1)   # → (batch, leads, time)\n",
    "        x = self.cnn(x)\n",
    "        x = x.permute(0, 2, 1)   # → (batch, time, features)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34c48ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG_CNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = CNNFeatureExtractor()   # from main_cnn\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=64,\n",
    "            hidden_size=128,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # morphology learning\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        # rhythm learning\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        # temporal pooling (VERY IMPORTANT)\n",
    "        out = out.mean(dim=1)\n",
    "\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec897fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample_ids(ids, n, seed=42):\n",
    "    ids = np.array(ids)\n",
    "    if len(ids) < n:\n",
    "        raise ValueError(f\"Requested {n}, but only {len(ids)} available\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return rng.choice(ids, size=n, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac00e088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial pool sizes:\n",
      "0 8329\n",
      "1 1027\n",
      "2 32\n",
      "3 2394\n"
     ]
    }
   ],
   "source": [
    "ecg_pool = {\n",
    "    0: set(norm_ids),\n",
    "    1: set(afib_ids),\n",
    "    2: set(aflt_ids),\n",
    "    3: set(other_ids)\n",
    "}\n",
    "\n",
    "print(\"Initial pool sizes:\")\n",
    "for k, v in ecg_pool.items():\n",
    "    print(k, len(v))\n",
    "\n",
    "TRAIN_COUNTS = {\n",
    "    0: 1500,  # NORM\n",
    "    1: 500,   # AFIB\n",
    "    2: 15,  # AFLT\n",
    "    3: 500    # OTHER\n",
    "}\n",
    "TEST_COUNTS = {\n",
    "    0: 300,\n",
    "    1: 100,\n",
    "    2: 15,   \n",
    "    3: 100\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "897a4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = []\n",
    "\n",
    "for label, n in TRAIN_COUNTS.items():\n",
    "    ids = select_from_pool(ecg_pool, label, n)\n",
    "    train_ids.extend([(eid, label) for eid in ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09ef02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = []\n",
    "\n",
    "for label, n in TEST_COUNTS.items():\n",
    "    ids = select_from_pool(ecg_pool, label, n)\n",
    "    test_ids.extend([(eid, label) for eid in ids])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a820de",
   "metadata": {},
   "source": [
    "### Verifiction of no mixing of traingin and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60d5092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap: 0\n"
     ]
    }
   ],
   "source": [
    "train_set = set(eid for eid, _ in train_ids)\n",
    "test_set  = set(eid for eid, _ in test_ids)\n",
    "\n",
    "print(\"Overlap:\", len(train_set & test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cfbae1",
   "metadata": {},
   "source": [
    "### Loader of ECG array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f5bfed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arrays(id_label_list):\n",
    "    X, y = [], []\n",
    "    for ecg_id, label in id_label_list:\n",
    "        X.append(load_ecg_fast(ecg_id))\n",
    "        y.append(label)\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c3d1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = build_arrays(train_ids)\n",
    "X_test,  y_test  = build_arrays(test_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0de9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ea5a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ECGDataset(X_train, y_train)\n",
    "test_dataset  = ECGDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "41de0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ECG_CNN_LSTM(num_classes=4).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aef2773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
