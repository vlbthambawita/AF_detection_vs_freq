{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374165d6",
   "metadata": {},
   "source": [
    "# This Expermental take CNN-adrian with LSTM model\n",
    ">CNN Learn feature of ECG morphology\n",
    ">LSTM deccide the AFIB, NORM, AFLAT, OTHER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5d47c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "c:\\Users\\arjan\\Documents\\GitHub\\SEARCH_AF_detection_OsloMet_BachelorGroup\\venv\\Lib\\site-packages\\torch\\__init__.py\n",
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Dataset loader & preparation\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import random\n",
    "from collections import Counter\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "print(torch.__file__)\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(\"../../../data/ptbxl_database.csv\")\n",
    "\n",
    "\n",
    "ecg_ids = []\n",
    "labels = []\n",
    "patient_ids = []\n",
    "\n",
    "\n",
    "norm_ids  = []\n",
    "afib_ids  = []\n",
    "aflt_ids  = []\n",
    "other_ids = []\n",
    "\n",
    "def get_label(scp_codes):\n",
    "    if \"AFIB\" in scp_codes:\n",
    "        return 1\n",
    "    if \"NORM\" in scp_codes:\n",
    "        return 0\n",
    "    if \"AFLT\" in scp_codes:\n",
    "        return 2\n",
    "    \n",
    "    if \"NDT\" in scp_codes:\n",
    "        return 4\n",
    "    if \"NST_\" in scp_codes:\n",
    "        return 5\n",
    "    if \"SVARR\" in scp_codes:\n",
    "        return 6\n",
    "    if \"SVTAC\" in scp_codes:\n",
    "        return 7\n",
    "    if \"PAC\" in scp_codes:\n",
    "        return 8\n",
    "    return None\n",
    "\n",
    "\n",
    "LABEL_MAP = {\n",
    "    \"NORM\": 0,\n",
    "    \"AFIB\": 1,\n",
    "    \"OTHER\": 0\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6724fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FASTER for loading ECG files\n",
    "def build_ecg_index(root=\"../../../data/records500\", suffix=\"_hr\"):\n",
    "    index = {}\n",
    "    for p in Path(root).rglob(f\"*{suffix}.hea\"):\n",
    "        ecg_id = int(p.stem.replace(suffix, \"\"))\n",
    "        index[ecg_id] = str(p.with_suffix(\"\"))\n",
    "    return index\n",
    "\n",
    "ECG_INDEX = build_ecg_index()\n",
    "\n",
    "def load_ecg_fast(ecg_id):\n",
    "    record = wfdb.rdrecord(ECG_INDEX[ecg_id])\n",
    "    return record.p_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0483ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_main_label(scp_codes_str: str) -> str:\n",
    "    codes = ast.literal_eval(scp_codes_str)  # dict\n",
    "    if \"AFIB\" in codes:\n",
    "        return \"AFIB\"\n",
    "    elif \"NORM\" in codes:\n",
    "        return \"NORM\"\n",
    "    else:\n",
    "        return \"OTHER\"\n",
    "\n",
    "dff[\"ecg_label\"] = dff[\"scp_codes\"].apply(extract_main_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abd7d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_label(ecg_labels) -> str:\n",
    "    s = set(ecg_labels)\n",
    "    if \"AFIB\" in s:\n",
    "        return \"AFIB\"\n",
    "    elif \"NORM\" in s:\n",
    "        return \"NORM\"\n",
    "    else:\n",
    "        return \"OTHER\"\n",
    "\n",
    "patient_df = (\n",
    "    dff.groupby(\"patient_id\")[\"ecg_label\"]\n",
    "       .apply(patient_label)\n",
    "       .reset_index()\n",
    "       .rename(columns={\"ecg_label\": \"patient_label\"})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35524dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient counts:\n",
      "NORM : 8831\n",
      "AFIB : 1245\n",
      "OTHER: 8809\n"
     ]
    }
   ],
   "source": [
    "norm_patients  = patient_df.loc[patient_df.patient_label == \"NORM\",  \"patient_id\"].values\n",
    "afib_patients  = patient_df.loc[patient_df.patient_label == \"AFIB\",  \"patient_id\"].values\n",
    "other_patients = patient_df.loc[patient_df.patient_label == \"OTHER\", \"patient_id\"].values\n",
    "\n",
    "print(\"Patient counts:\")\n",
    "print(\"NORM :\", len(norm_patients))\n",
    "print(\"AFIB :\", len(afib_patients))\n",
    "print(\"OTHER:\", len(other_patients))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a247f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# ---- Train patients ----\n",
    "train_norm  = np.random.choice(norm_patients, 500, replace=False)\n",
    "train_afib  = np.random.choice(afib_patients, 500, replace=False)\n",
    "train_other = np.random.choice(other_patients, 500, replace=False)\n",
    "\n",
    "# remaining pools\n",
    "rem_norm  = np.setdiff1d(norm_patients, train_norm)\n",
    "rem_afib  = np.setdiff1d(afib_patients, train_afib)\n",
    "rem_other = np.setdiff1d(other_patients, train_other)\n",
    "\n",
    "# ---- Test patients ----\n",
    "test_norm  = np.random.choice(rem_norm, 100, replace=False)\n",
    "test_afib  = np.random.choice(rem_afib, 100, replace=False)\n",
    "test_other = np.random.choice(rem_other, 100, replace=False)\n",
    "\n",
    "train_patients = np.concatenate([train_norm, train_afib, train_other])\n",
    "test_patients  = np.concatenate([test_norm,  test_afib,  test_other])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "911d7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AF = 1 \n",
    "NONAF = 0\n",
    "train_labels = np.concatenate([\n",
    "    np.full(len(train_norm),  NONAF,  dtype=int),\n",
    "    np.full(len(train_afib),  AF,  dtype=int),\n",
    "    np.full(len(train_other), NONAF, dtype=int),\n",
    "])\n",
    "\n",
    "test_labels = np.concatenate([\n",
    "    np.full(len(test_norm),  NONAF,  dtype=int),\n",
    "    np.full(len(test_afib),  AF,  dtype=int),\n",
    "    np.full(len(test_other), NONAF, dtype=int),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d74e0cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train patients: 1500\n",
      "Test patients : 300\n",
      "Overlap (must be 0): 0\n",
      "Train label counts: [1000  500]\n",
      "Test label counts : [200 100]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train patients:\", len(train_patients))\n",
    "print(\"Test patients :\", len(test_patients))\n",
    "print(\"Overlap (must be 0):\", len(np.intersect1d(train_patients, test_patients)))\n",
    "\n",
    "print(\"Train label counts:\", np.bincount(train_labels))\n",
    "print(\"Test label counts :\", np.bincount(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb077288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dff[\"label_id\"] = dff[\"ecg_label\"].map(LABEL_MAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1636f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dff[dff[\"patient_id\"].isin(train_patients)].copy()\n",
    "test_df  = dff[dff[\"patient_id\"].isin(test_patients)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ff117e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    set(train_df.patient_id).isdisjoint(set(test_df.patient_id))\n",
    "), \"❌ Patient leakage detected!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4e753c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN ECG distribution:\n",
      "ecg_label\n",
      "OTHER    667\n",
      "AFIB     593\n",
      "NORM     556\n",
      "Name: count, dtype: int64\n",
      "\n",
      "TEST ECG distribution:\n",
      "ecg_label\n",
      "OTHER    139\n",
      "AFIB     123\n",
      "NORM     109\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN ECG distribution:\")\n",
    "print(train_df[\"ecg_label\"].value_counts())\n",
    "\n",
    "print(\"\\nTEST ECG distribution:\")\n",
    "print(test_df[\"ecg_label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3105b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ecg(ecg):\n",
    "    mean = ecg.mean(axis=0)\n",
    "    std = ecg.std(axis=0) + 1e-8\n",
    "    return (ecg - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20690e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        ecg = load_ecg_fast(row.ecg_id)\n",
    "        ecg = normalize_ecg(ecg)\n",
    "\n",
    "        label = row.label_id\n",
    "\n",
    "        return (\n",
    "            torch.tensor(ecg, dtype=torch.float32),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04eb10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "\n",
    "train_dataset = ECGDataset(train_df)\n",
    "test_dataset  = ECGDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9db5b695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5000, 12])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b49044cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    return total_loss / len(loader), correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56c9743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_with_metrics(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        pred = out.argmax(dim=1)\n",
    "        y_true.extend(y.cpu().numpy().tolist())\n",
    "        y_pred.extend(pred.cpu().numpy().tolist())\n",
    "\n",
    "    val_loss = total_loss / len(loader)\n",
    "    val_acc  = (np.array(y_true) == np.array(y_pred)).mean()\n",
    "    val_f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    val_rec_af = recall_score(y_true, y_pred, pos_label=1, zero_division=0)  # AF sensitivity\n",
    "\n",
    "    return val_loss, val_acc, val_f1, val_rec_af\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f79aaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Learns ECG morphology:\n",
    "    QRS complex shape, amplitude, local waveform patterns\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(12, 32, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, time, leads)\n",
    "        x = x.permute(0, 2, 1)   # → (batch, leads, time)\n",
    "        x = self.cnn(x)\n",
    "        x = x.permute(0, 2, 1)   # → (batch, time, features)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34c48ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG_CNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = CNNFeatureExtractor()   # from main_cnn\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=64,\n",
    "            hidden_size=128,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # morphology learning\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        # rhythm learning\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        # temporal pooling (VERY IMPORTANT)\n",
    "        out = out.mean(dim=1)\n",
    "\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32b677bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "447d719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "fold_results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "daf8c502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ FOLD 1 =================\n",
      "Fold 1 class counts [nonAF, AF]: [800 400] | weights: [1.0, 2.0]\n",
      "Fold 1 | Epoch 01 | Train Loss 0.6518 | Train Acc 0.617 | Val Loss 0.5814 | Val Acc 0.704 | Val F1 0.576 | Val Rec AF 0.626 | Best Val 0.704 (ep 1)\n",
      "Fold 1 | Epoch 02 | Train Loss 0.5932 | Train Acc 0.699 | Val Loss 0.5722 | Val Acc 0.684 | Val F1 0.614 | Val Rec AF 0.783 | Best Val 0.704 (ep 1)\n",
      "Fold 1 | Epoch 03 | Train Loss 0.5741 | Train Acc 0.702 | Val Loss 0.5214 | Val Acc 0.726 | Val F1 0.642 | Val Rec AF 0.765 | Best Val 0.726 (ep 3)\n",
      "Fold 1 | Epoch 04 | Train Loss 0.5306 | Train Acc 0.735 | Val Loss 0.5060 | Val Acc 0.785 | Val F1 0.624 | Val Rec AF 0.557 | Best Val 0.785 (ep 4)\n",
      "\n",
      "================ FOLD 2 =================\n",
      "Fold 2 class counts [nonAF, AF]: [800 400] | weights: [1.0, 2.0]\n",
      "Fold 2 | Epoch 01 | Train Loss 0.6330 | Train Acc 0.670 | Val Loss 0.6058 | Val Acc 0.680 | Val F1 0.547 | Val Rec AF 0.603 | Best Val 0.680 (ep 1)\n",
      "Fold 2 | Epoch 02 | Train Loss 0.5851 | Train Acc 0.706 | Val Loss 0.5820 | Val Acc 0.701 | Val F1 0.609 | Val Rec AF 0.727 | Best Val 0.701 (ep 2)\n",
      "Fold 2 | Epoch 03 | Train Loss 0.5408 | Train Acc 0.736 | Val Loss 0.5853 | Val Acc 0.720 | Val F1 0.629 | Val Rec AF 0.744 | Best Val 0.720 (ep 3)\n",
      "Fold 2 | Epoch 04 | Train Loss 0.4449 | Train Acc 0.796 | Val Loss 0.4974 | Val Acc 0.820 | Val F1 0.714 | Val Rec AF 0.702 | Best Val 0.820 (ep 4)\n",
      "\n",
      "================ FOLD 3 =================\n",
      "Fold 3 class counts [nonAF, AF]: [800 400] | weights: [1.0, 2.0]\n",
      "Fold 3 | Epoch 01 | Train Loss 0.6513 | Train Acc 0.618 | Val Loss 0.6033 | Val Acc 0.700 | Val F1 0.470 | Val Rec AF 0.398 | Best Val 0.700 (ep 1)\n",
      "Fold 3 | Epoch 02 | Train Loss 0.6038 | Train Acc 0.684 | Val Loss 0.5569 | Val Acc 0.722 | Val F1 0.562 | Val Rec AF 0.534 | Best Val 0.722 (ep 2)\n",
      "Fold 3 | Epoch 03 | Train Loss 0.5821 | Train Acc 0.694 | Val Loss 0.5425 | Val Acc 0.700 | Val F1 0.624 | Val Rec AF 0.746 | Best Val 0.722 (ep 2)\n",
      "Fold 3 | Epoch 04 | Train Loss 0.5678 | Train Acc 0.709 | Val Loss 0.5301 | Val Acc 0.756 | Val F1 0.606 | Val Rec AF 0.559 | Best Val 0.756 (ep 4)\n",
      "\n",
      "================ FOLD 4 =================\n",
      "Fold 4 class counts [nonAF, AF]: [800 400] | weights: [1.0, 2.0]\n",
      "Fold 4 | Epoch 01 | Train Loss 0.6556 | Train Acc 0.601 | Val Loss 0.6316 | Val Acc 0.644 | Val F1 0.586 | Val Rec AF 0.783 | Best Val 0.644 (ep 1)\n",
      "Fold 4 | Epoch 02 | Train Loss 0.5831 | Train Acc 0.707 | Val Loss 0.6058 | Val Acc 0.655 | Val F1 0.597 | Val Rec AF 0.791 | Best Val 0.655 (ep 2)\n",
      "Fold 4 | Epoch 03 | Train Loss 0.5643 | Train Acc 0.718 | Val Loss 0.6727 | Val Acc 0.557 | Val F1 0.578 | Val Rec AF 0.939 | Best Val 0.655 (ep 2)\n",
      "Fold 4 | Epoch 04 | Train Loss 0.5436 | Train Acc 0.747 | Val Loss 0.5350 | Val Acc 0.728 | Val F1 0.650 | Val Rec AF 0.783 | Best Val 0.728 (ep 4)\n",
      "\n",
      "================ FOLD 5 =================\n",
      "Fold 5 class counts [nonAF, AF]: [800 400] | weights: [1.0, 2.0]\n",
      "Fold 5 | Epoch 01 | Train Loss 0.6415 | Train Acc 0.596 | Val Loss 0.5966 | Val Acc 0.714 | Val F1 0.598 | Val Rec AF 0.637 | Best Val 0.714 (ep 1)\n",
      "Fold 5 | Epoch 02 | Train Loss 0.5967 | Train Acc 0.670 | Val Loss 0.5874 | Val Acc 0.695 | Val F1 0.577 | Val Rec AF 0.621 | Best Val 0.714 (ep 1)\n",
      "Fold 5 | Epoch 03 | Train Loss 0.5409 | Train Acc 0.725 | Val Loss 0.6844 | Val Acc 0.757 | Val F1 0.591 | Val Rec AF 0.524 | Best Val 0.757 (ep 3)\n",
      "Fold 5 | Epoch 04 | Train Loss 0.5079 | Train Acc 0.775 | Val Loss 0.4856 | Val Acc 0.751 | Val F1 0.693 | Val Rec AF 0.839 | Best Val 0.757 (ep 3)\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(\n",
    "    skf.split(train_patients, train_labels)\n",
    "):\n",
    "\n",
    "    print(f\"\\n================ FOLD {fold+1} =================\")\n",
    "\n",
    "    fold_train_patients = train_patients[train_idx]\n",
    "    fold_val_patients   = train_patients[val_idx]\n",
    "\n",
    "    fold_train_df = dff[dff.patient_id.isin(fold_train_patients)]\n",
    "    fold_val_df   = dff[dff.patient_id.isin(fold_val_patients)]\n",
    "\n",
    "    train_ds = ECGDataset(fold_train_df)\n",
    "    val_ds   = ECGDataset(fold_val_df)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    # ✅ binary model (labels are 0/1)\n",
    "    model = ECG_CNN_LSTM(num_classes=2).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # ✅ HERE: compute class weights from THIS fold's training labels\n",
    "    counts = np.bincount(train_labels[train_idx], minlength=2)   # [nonAF, AF]\n",
    "    w0 = 1.0\n",
    "    w1 = counts[0] / max(counts[1], 1)  # e.g. 2.0 if 2:1\n",
    "    class_weights = torch.tensor([w0, w1], dtype=torch.float32).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    print(f\"Fold {fold+1} class counts [nonAF, AF]: {counts} | weights: {[w0, float(w1)]:}\")\n",
    "\n",
    "    best_val_acc = -1.0\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, optimizer, criterion, device\n",
    "        )\n",
    "\n",
    "        val_loss, val_acc, val_f1, val_rec_af = validate_with_metrics(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), f\"best_model_fold_{fold}.pt\")\n",
    "\n",
    "        print(\n",
    "            f\"Fold {fold+1} | Epoch {epoch+1:02d} | \"\n",
    "            f\"Train Loss {train_loss:.4f} | Train Acc {train_acc:.3f} | \"\n",
    "            f\"Val Loss {val_loss:.4f} | Val Acc {val_acc:.3f} | \"\n",
    "            f\"Val F1 {val_f1:.3f} | Val Rec AF {val_rec_af:.3f} | \"\n",
    "            f\"Best Val {best_val_acc:.3f} (ep {best_epoch})\"\n",
    "        )\n",
    "\n",
    "    fold_results.append(best_val_acc)  # usually better than last epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49583b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Cross-Validation Result =====\n",
      "Fold accuracies: [np.float64(0.7849162011173184), np.float64(0.8201058201058201), np.float64(0.7563739376770539), np.float64(0.7282913165266106), np.float64(0.7567567567567568)]\n",
      "Mean accuracy: 0.7692888064367119\n",
      "Std: 0.031084480455489973\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Cross-Validation Result =====\")\n",
    "print(\"Fold accuracies:\", fold_results)\n",
    "print(\"Mean accuracy:\", np.mean(fold_results))\n",
    "print(\"Std:\", np.std(fold_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "655d29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_to_markdown_binary(cm):\n",
    "    cm = np.asarray(cm, dtype=int)\n",
    "    TN, FP = cm[0]\n",
    "    FN, TP = cm[1]\n",
    "\n",
    "    total = cm.sum()\n",
    "    accuracy = (TP + TN) / total if total > 0 else 0.0\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0.0\n",
    "    fp_rate = FP / (FP + TN) if (FP + TN) > 0 else 0.0\n",
    "\n",
    "    md = []\n",
    "    md.append(\"## Model Evaluation Results (Binary AF Detection)\\n\")\n",
    "    md.append(\"### Overall Performance\")\n",
    "    md.append(f\"- **Total test samples:** {total}\")\n",
    "    md.append(f\"- **Overall accuracy:** **{accuracy*100:.1f}%**\\n\")\n",
    "\n",
    "    md.append(\"### Binary Classification Metrics\")\n",
    "    md.append(f\"- **AF sensitivity (recall):** **{sensitivity*100:.1f}%**\")\n",
    "    md.append(f\"- **Non-AF specificity:** **{specificity*100:.1f}%**\")\n",
    "    md.append(f\"- **False AF alarm rate:** **{fp_rate*100:.1f}%**\\n\")\n",
    "\n",
    "    md.append(\"### Confusion Matrix Interpretation\")\n",
    "    md.append(f\"- **True Positives (AF correctly detected):** {TP}\")\n",
    "    md.append(f\"- **False Negatives (missed AF):** {FN}\")\n",
    "    md.append(f\"- **False Positives (non-AF classified as AF):** {FP}\")\n",
    "    md.append(f\"- **True Negatives (correct non-AF rejection):** {TN}\")\n",
    "\n",
    "    return \"\\n\".join(md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9791d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train record counts [nonAF, AF]: [1223  593] | weights: [1.0, 2.0623946037099494]\n",
      "Epoch 01 | Train Loss 0.6219 | Train Acc 0.660\n",
      "Epoch 02 | Train Loss 0.5569 | Train Acc 0.719\n",
      "Epoch 03 | Train Loss 0.5080 | Train Acc 0.784\n",
      "Epoch 04 | Train Loss 0.6532 | Train Acc 0.675\n",
      "\n",
      "===== FINAL TEST RESULT =====\n",
      "Test accuracy : 0.7223719676549866\n",
      "Test F1       : 0.5795918367346938\n",
      "AF Recall     : 0.5772357723577236\n",
      "Confusion matrix [[TN FP],[FN TP]]:\n",
      " [[197  51]\n",
      " [ 52  71]]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Model Evaluation Results (Binary AF Detection)\n",
       "\n",
       "### Overall Performance\n",
       "- **Total test samples:** 371\n",
       "- **Overall accuracy:** **72.2%**\n",
       "\n",
       "### Binary Classification Metrics\n",
       "- **AF sensitivity (recall):** **57.7%**\n",
       "- **Non-AF specificity:** **79.4%**\n",
       "- **False AF alarm rate:** **20.6%**\n",
       "\n",
       "### Confusion Matrix Interpretation\n",
       "- **True Positives (AF correctly detected):** 71\n",
       "- **False Negatives (missed AF):** 52\n",
       "- **False Positives (non-AF classified as AF):** 51\n",
       "- **True Negatives (correct non-AF rejection):** 197"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "\n",
    "# --- Build final dataframes (hold-out by patient) ---\n",
    "final_train_df = dff[dff.patient_id.isin(train_patients)].copy()\n",
    "final_test_df  = dff[dff.patient_id.isin(test_patients)].copy()\n",
    "\n",
    "assert set(final_train_df.patient_id).isdisjoint(set(final_test_df.patient_id)), \"Leakage in final split!\"\n",
    "\n",
    "# --- Dedicated final loaders (do NOT reuse train_loader from CV) ---\n",
    "final_train_loader = DataLoader(\n",
    "    ECGDataset(final_train_df),\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "final_test_loader = DataLoader(\n",
    "    ECGDataset(final_test_df),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# --- Fresh model ---\n",
    "model = ECG_CNN_LSTM(num_classes=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# --- Class weights from FINAL TRAIN RECORD labels ---\n",
    "counts = np.bincount(final_train_df[\"label_id\"].values, minlength=2)\n",
    "w0 = 1.0\n",
    "w1 = counts[0] / max(counts[1], 1)\n",
    "class_weights = torch.tensor([w0, w1], dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "print(\"Final train record counts [nonAF, AF]:\", counts, \"| weights:\", [float(w0), float(w1)])\n",
    "\n",
    "# --- Train ---\n",
    "EPOCHS_FINAL = 4\n",
    "for epoch in range(EPOCHS_FINAL):\n",
    "    train_loss, train_acc = train_one_epoch(model, final_train_loader, optimizer, criterion, device)\n",
    "    print(f\"Epoch {epoch+1:02d} | Train Loss {train_loss:.4f} | Train Acc {train_acc:.3f}\")\n",
    "\n",
    "# --- Test ---\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in final_test_loader:\n",
    "        X = X.to(device)\n",
    "        out = model(X)\n",
    "        preds = out.argmax(dim=1).cpu().numpy()\n",
    "        y_pred.extend(preds.tolist())\n",
    "        y_true.extend(y.numpy().tolist())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "test_acc = (y_true == y_pred).mean()\n",
    "test_f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "test_rec_af = recall_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "\n",
    "print(\"\\n===== FINAL TEST RESULT =====\")\n",
    "print(\"Test accuracy :\", float(test_acc))\n",
    "print(\"Test F1       :\", float(test_f1))\n",
    "print(\"AF Recall     :\", float(test_rec_af))\n",
    "print(\"Confusion matrix [[TN FP],[FN TP]]:\\n\", cm)\n",
    "\n",
    "display(Markdown(confusion_matrix_to_markdown_binary(cm)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
