{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374165d6",
   "metadata": {},
   "source": [
    "# This Expermental take CNN-adrian with LSTM model\n",
    ">CNN Learn feature of ECG morphology\n",
    ">LSTM deccide the AFIB, NORM, AFLAT, OTHER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5d47c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "c:\\Users\\arjan\\Documents\\GitHub\\SEARCH_AF_detection_OsloMet_BachelorGroup\\venv\\Lib\\site-packages\\torch\\__init__.py\n",
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Dataset loader & preparation\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import random\n",
    "from collections import Counter\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "dff = pd.read_csv(\"../../../data/ptbxl_database.csv\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "print(torch.__file__)\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e02d1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LABELS = {\"NORM\", \"AFIB\", \"AFLT\"}\n",
    "\n",
    "\n",
    "norm_ids  = []\n",
    "afib_ids  = []\n",
    "aflt_ids  = []\n",
    "other_ids = []\n",
    "\n",
    "\n",
    "LABEL_MAP = {\n",
    "    \"NORM\": 0,\n",
    "    \"AFIB\": 1,\n",
    "    \"AFLT\": 2,\n",
    "    \"OTHER\": 3\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ade0d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_repeated_label(label_sets):\n",
    "    # label_sets = list of sets, one per ECG\n",
    "    all_labels = []\n",
    "    for s in label_sets:\n",
    "        all_labels.extend(list(s))\n",
    "\n",
    "    counts = Counter(all_labels)\n",
    "\n",
    "    # label appears in 2 or more recordings\n",
    "    return any(v >= 2 for v in counts.values())\n",
    "\n",
    "\n",
    "\n",
    "def extract_labels(scp_codes):\n",
    "    codes = ast.literal_eval(scp_codes)\n",
    "    return set(codes.keys()) & TARGET_LABELS\n",
    "\n",
    "def select_from_pool(pool, label, n, seed=42):\n",
    "    \"\"\"\n",
    "    Select n ECG IDs from pool[label] and REMOVE them.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    available = list(pool[label])\n",
    "\n",
    "    if len(available) < n:\n",
    "        raise ValueError(\n",
    "            f\"Not enough ECGs for label {label}. \"\n",
    "            f\"Requested {n}, available {len(available)}\"\n",
    "        )\n",
    "\n",
    "    selected = random.sample(available, n)\n",
    "\n",
    "    # remove selected from pool\n",
    "    pool[label] -= set(selected)\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6724fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FASTER for loading ECG files\n",
    "def build_ecg_index(root=\"../../../data/records500\", suffix=\"_hr\"):\n",
    "    index = {}\n",
    "    for p in Path(root).rglob(f\"*{suffix}.hea\"):\n",
    "        ecg_id = int(p.stem.replace(suffix, \"\"))\n",
    "        index[ecg_id] = str(p.with_suffix(\"\"))\n",
    "    return index\n",
    "\n",
    "ECG_INDEX = build_ecg_index()\n",
    "\n",
    "def load_ecg_fast(ecg_id):\n",
    "    record = wfdb.rdrecord(ECG_INDEX[ecg_id])\n",
    "    return record.p_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "790c4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arrays(id_label_list):\n",
    "    X, y = [], []\n",
    "    for ecg_id, label in id_label_list:\n",
    "        X.append(load_ecg_fast(ecg_id))\n",
    "        y.append(label)\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f3d881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ECG records: 21837\n",
      "Total patients: 18885\n",
      "Patients with multiple recordings: 2127\n",
      "Max recordings for one patient: 10\n",
      "Patients with multiple labels: 269\n",
      "Percentage: 1.4%\n"
     ]
    }
   ],
   "source": [
    "#Ensure if patient_id have different ECG records, all records are in the same set\n",
    "ecg_records = dff[\"ecg_id\"].count() \n",
    "print(\"Total ECG records:\", ecg_records)\n",
    "patient_ids = dff[\"patient_id\"].value_counts()\n",
    "multiple_recordings = patient_ids[patient_ids > 1]\n",
    "print(\"Total patients:\", dff[\"patient_id\"].nunique())\n",
    "print(\"Patients with multiple recordings:\", len(multiple_recordings))\n",
    "print(\"Max recordings for one patient:\", multiple_recordings.max())\n",
    "\n",
    "def get_label(scp_codes):\n",
    "    if \"AFIB\" in scp_codes:\n",
    "        return 1\n",
    "    if \"NORM\" in scp_codes:\n",
    "        return 0\n",
    "    if \"AFLT\" in scp_codes:\n",
    "        return 2\n",
    "    \n",
    "    if \"NDT\" in scp_codes:\n",
    "        return 4\n",
    "    if \"NST_\" in scp_codes:\n",
    "        return 5\n",
    "    if \"SVARR\" in scp_codes:\n",
    "        return 6\n",
    "    if \"SVTAC\" in scp_codes:\n",
    "        return 7\n",
    "    if \"PAC\" in scp_codes:\n",
    "        return 8\n",
    "    return None\n",
    "\n",
    "dff[\"label\"] = dff[\"scp_codes\"].apply(lambda x: get_label(ast.literal_eval(x)))\n",
    "label_counts_per_patient = dff.groupby(\"patient_id\")[\"label\"].nunique()\n",
    "patients_with_label_change = label_counts_per_patient[label_counts_per_patient > 1]\n",
    "\n",
    "print(\"Patients with multiple labels:\", len(patients_with_label_change))\n",
    "print(\n",
    "    \"Percentage:\",\n",
    "    f\"{round(100 * len(patients_with_label_change) / dff['patient_id'].nunique(), 1)}%\"\n",
    ")\n",
    "\n",
    "\n",
    "dff[\"target_labels\"] = dff[\"scp_codes\"].apply(extract_labels)\n",
    "dff_target = dff[dff[\"target_labels\"].apply(len) > 0]\n",
    "\n",
    "\n",
    "patient_groups = dff_target.groupby(\"patient_id\")[\"target_labels\"]\n",
    "\n",
    "\n",
    "patients_with_repeated_label = patient_groups.apply(has_repeated_label)\n",
    "# patients with more than one ECG\n",
    "patient_target_counts = dff_target[\"patient_id\"].value_counts()\n",
    "\n",
    "patients_with_multiple_target_ecgs = patient_target_counts[\n",
    "    patient_target_counts > 1\n",
    "].index\n",
    "dff_final = dff_target[\n",
    "    dff_target[\"patient_id\"].isin(patients_with_multiple_target_ecgs)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf62d6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORM : 8329\n",
      "AFIB : 1027\n",
      "AFLT : 32\n",
      "OTHER: 2394\n",
      "TOTAL: 11782\n"
     ]
    }
   ],
   "source": [
    "dataset_root = \"../../../data/\"\n",
    "df = pd.read_csv(os.path.join(dataset_root, \"ptbxl_database.csv\"))\n",
    "for _, row in df.iterrows():\n",
    "    \n",
    "    scp_codes = ast.literal_eval(row[\"scp_codes\"])\n",
    "    label = get_label(scp_codes)\n",
    "    ecg_id = row[\"ecg_id\"]\n",
    "    p_id = row[\"patient_id\"]\n",
    "    if p_id  in dff_final[\"patient_id\"].values:\n",
    "        continue\n",
    "\n",
    "    if label is None:\n",
    "        continue\n",
    "\n",
    "\n",
    "    if label == 0:\n",
    "        norm_ids.append(ecg_id)\n",
    "\n",
    "    elif label == 1:\n",
    "        afib_ids.append(ecg_id)\n",
    "\n",
    "    elif label == 2:\n",
    "        aflt_ids.append(ecg_id)\n",
    "\n",
    "    else:\n",
    "        other_ids.append(ecg_id)\n",
    "print(\"NORM :\", len(norm_ids))\n",
    "print(\"AFIB :\", len(afib_ids))\n",
    "print(\"AFLT :\", len(aflt_ids))\n",
    "print(\"OTHER:\", len(other_ids))\n",
    "print(\"TOTAL:\", len(norm_ids) + len(afib_ids) + len(aflt_ids) + len(other_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f79aaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Learns ECG morphology:\n",
    "    QRS complex shape, amplitude, local waveform patterns\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(12, 32, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, time, leads)\n",
    "        x = x.permute(0, 2, 1)   # → (batch, leads, time)\n",
    "        x = self.cnn(x)\n",
    "        x = x.permute(0, 2, 1)   # → (batch, time, features)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34c48ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG_CNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = CNNFeatureExtractor()   # from main_cnn\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=64,\n",
    "            hidden_size=128,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # morphology learning\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        # rhythm learning\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        # temporal pooling (VERY IMPORTANT)\n",
    "        out = out.mean(dim=1)\n",
    "\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec897fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample_ids(ids, n, seed=42):\n",
    "    ids = np.array(ids)\n",
    "    if len(ids) < n:\n",
    "        raise ValueError(f\"Requested {n}, but only {len(ids)} available\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return rng.choice(ids, size=n, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac00e088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial pool sizes:\n",
      "0 8329\n",
      "1 1027\n",
      "2 32\n",
      "3 2394\n"
     ]
    }
   ],
   "source": [
    "ecg_pool = {\n",
    "    0: set(norm_ids),\n",
    "    1: set(afib_ids),\n",
    "    2: set(aflt_ids),\n",
    "    3: set(other_ids)\n",
    "}\n",
    "\n",
    "print(\"Initial pool sizes:\")\n",
    "for k, v in ecg_pool.items():\n",
    "    print(k, len(v))\n",
    "\n",
    "TRAIN_COUNTS = {\n",
    "    0: 1500,  # NORM\n",
    "    1: 500,   # AFIB\n",
    "    2: 15,  # AFLT\n",
    "    3: 500    # OTHER\n",
    "}\n",
    "TEST_COUNTS = {\n",
    "    0: 300,\n",
    "    1: 100,\n",
    "    2: 15,   \n",
    "    3: 100\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "897a4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = []\n",
    "\n",
    "for label, n in TRAIN_COUNTS.items():\n",
    "    ids = select_from_pool(ecg_pool, label, n)\n",
    "    train_ids.extend([(eid, label) for eid in ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09ef02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = []\n",
    "\n",
    "for label, n in TEST_COUNTS.items():\n",
    "    ids = select_from_pool(ecg_pool, label, n)\n",
    "    test_ids.extend([(eid, label) for eid in ids])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a820de",
   "metadata": {},
   "source": [
    "### Verifiction of no mixing of traingin and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60d5092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap: 0\n"
     ]
    }
   ],
   "source": [
    "train_set = set(eid for eid, _ in train_ids)\n",
    "test_set  = set(eid for eid, _ in test_ids)\n",
    "\n",
    "print(\"Overlap:\", len(train_set & test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cfbae1",
   "metadata": {},
   "source": [
    "### Loader of ECG array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f5bfed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arrays(id_label_list):\n",
    "    X, y = [], []\n",
    "    for ecg_id, label in id_label_list:\n",
    "        X.append(load_ecg_fast(ecg_id))\n",
    "        y.append(label)\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c3d1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = build_arrays(train_ids)\n",
    "X_test,  y_test  = build_arrays(test_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0de9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ea5a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ECGDataset(X_train, y_train)\n",
    "test_dataset  = ECGDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "41de0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ECG_CNN_LSTM(num_classes=4).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aef2773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566524ab",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a704a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 1.0293 | Train Acc: 0.581\n",
      "Epoch 02 | Loss: 0.7637 | Train Acc: 0.685\n",
      "Epoch 03 | Loss: 0.7087 | Train Acc: 0.710\n",
      "Epoch 04 | Loss: 0.7128 | Train Acc: 0.714\n",
      "Epoch 05 | Loss: 0.7009 | Train Acc: 0.711\n",
      "Epoch 06 | Loss: 0.6473 | Train Acc: 0.737\n",
      "Epoch 07 | Loss: 0.6973 | Train Acc: 0.734\n",
      "Epoch 08 | Loss: 0.7144 | Train Acc: 0.724\n",
      "Epoch 09 | Loss: 0.7265 | Train Acc: 0.708\n",
      "Epoch 10 | Loss: 0.6693 | Train Acc: 0.729\n",
      "Epoch 11 | Loss: 0.6468 | Train Acc: 0.750\n",
      "Epoch 12 | Loss: 0.6263 | Train Acc: 0.749\n",
      "Epoch 13 | Loss: 0.6165 | Train Acc: 0.757\n",
      "Epoch 14 | Loss: 0.5980 | Train Acc: 0.763\n",
      "Epoch 15 | Loss: 0.6341 | Train Acc: 0.756\n",
      "Epoch 16 | Loss: 0.6405 | Train Acc: 0.742\n",
      "Epoch 17 | Loss: 0.5712 | Train Acc: 0.768\n",
      "Epoch 18 | Loss: 0.6142 | Train Acc: 0.744\n",
      "Epoch 19 | Loss: 0.6040 | Train Acc: 0.754\n",
      "Epoch 20 | Loss: 0.5496 | Train Acc: 0.775\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    loader=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    epochs=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c1fbd2",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fef9c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, device):\n",
    "    model.eval()   # VERY IMPORTANT\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():  # disables gradients\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            logits = model(X_batch)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            y_true.extend(y_batch.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb2e417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = test_model(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "66455967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[272   1   0  27]\n",
      " [ 20  19   0  61]\n",
      " [  5   4   0   6]\n",
      " [ 36   2   0  62]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        NORM       0.82      0.91      0.86       300\n",
      "        AFIB       0.73      0.19      0.30       100\n",
      "        AFLT       0.00      0.00      0.00        15\n",
      "       OTHER       0.40      0.62      0.48       100\n",
      "\n",
      "    accuracy                           0.69       515\n",
      "   macro avg       0.49      0.43      0.41       515\n",
      "weighted avg       0.69      0.69      0.65       515\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arjan\\Documents\\GitHub\\SEARCH_AF_detection_OsloMet_BachelorGroup\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\arjan\\Documents\\GitHub\\SEARCH_AF_detection_OsloMet_BachelorGroup\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\arjan\\Documents\\GitHub\\SEARCH_AF_detection_OsloMet_BachelorGroup\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "labels = [0, 1, 2, 3]\n",
    "label_names = [\"NORM\", \"AFIB\", \"AFLT\", \"OTHER\"]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=label_names\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f4221c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_to_markdown(cm, label_names):\n",
    "    cm = np.asarray(cm, dtype=int)\n",
    "\n",
    "    total = cm.sum()\n",
    "    correct = np.trace(cm)\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "\n",
    "    supports = cm.sum(axis=1)\n",
    "\n",
    "    md = []\n",
    "\n",
    "    md.append(\"## Model Evaluation Results (Test Set)\\n\")\n",
    "    md.append(\n",
    "        \"The confusion matrix shows how the trained CNN–LSTM model classifies \"\n",
    "        \"unseen ECG recordings across four rhythm classes.\\n\"\n",
    "    )\n",
    "\n",
    "    # Overall performance\n",
    "    md.append(\"### Overall Performance\")\n",
    "    md.append(f\"- **Total test samples:** {total}\")\n",
    "    md.append(f\"- **Overall accuracy:** **{accuracy*100:.1f}%**\\n\")\n",
    "\n",
    "    # Dataset composition\n",
    "    md.append(\"### Test Set Composition\")\n",
    "    for i, name in enumerate(label_names):\n",
    "        md.append(f\"- **{name}:** {supports[i]} samples\")\n",
    "    md.append(\"\")\n",
    "\n",
    "    # Per-class results\n",
    "    md.append(\"### Per-class Results\\n\")\n",
    "\n",
    "    for i, name in enumerate(label_names):\n",
    "        support = supports[i]\n",
    "        tp = cm[i, i]\n",
    "        recall = tp / support if support > 0 else 0.0\n",
    "\n",
    "        md.append(f\"- **{name}**\")\n",
    "        md.append(f\"  - Correctly classified: **{tp} / {support}**\")\n",
    "        md.append(f\"  - **Recall:** **{recall*100:.1f}%**\")\n",
    "\n",
    "        row = cm[i].copy()\n",
    "        row[i] = 0\n",
    "\n",
    "        if support > 0 and row.sum() > 0:\n",
    "            top_idx = np.argsort(row)[::-1]\n",
    "            errors = []\n",
    "\n",
    "            for j in top_idx:\n",
    "                if row[j] > 0:\n",
    "                    pct = row[j] / support * 100\n",
    "                    errors.append(f\"{label_names[j]} ({pct:.1f}%)\")\n",
    "                if len(errors) == 2:\n",
    "                    break\n",
    "\n",
    "            md.append(\n",
    "                f\"  - Most errors were misclassified as **{', '.join(errors)}**.\"\n",
    "            )\n",
    "\n",
    "        md.append(\"\")\n",
    "\n",
    "    return \"\\n\".join(md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "747e8a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Model Evaluation Results (Test Set)\n",
       "\n",
       "The confusion matrix shows how the trained CNN–LSTM model classifies unseen ECG recordings across four rhythm classes.\n",
       "\n",
       "### Overall Performance\n",
       "- **Total test samples:** 515\n",
       "- **Overall accuracy:** **68.5%**\n",
       "\n",
       "### Test Set Composition\n",
       "- **NORM:** 300 samples\n",
       "- **AFIB:** 100 samples\n",
       "- **AFLT:** 15 samples\n",
       "- **OTHER:** 100 samples\n",
       "\n",
       "### Per-class Results\n",
       "\n",
       "- **NORM**\n",
       "  - Correctly classified: **272 / 300**\n",
       "  - **Recall:** **90.7%**\n",
       "  - Most errors were misclassified as **OTHER (9.0%), AFIB (0.3%)**.\n",
       "\n",
       "- **AFIB**\n",
       "  - Correctly classified: **19 / 100**\n",
       "  - **Recall:** **19.0%**\n",
       "  - Most errors were misclassified as **OTHER (61.0%), NORM (20.0%)**.\n",
       "\n",
       "- **AFLT**\n",
       "  - Correctly classified: **0 / 15**\n",
       "  - **Recall:** **0.0%**\n",
       "  - Most errors were misclassified as **OTHER (40.0%), NORM (33.3%)**.\n",
       "\n",
       "- **OTHER**\n",
       "  - Correctly classified: **62 / 100**\n",
       "  - **Recall:** **62.0%**\n",
       "  - Most errors were misclassified as **NORM (36.0%), AFIB (2.0%)**.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "markdown_report = confusion_matrix_to_markdown(cm, label_names)\n",
    "\n",
    "display(Markdown(markdown_report))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
