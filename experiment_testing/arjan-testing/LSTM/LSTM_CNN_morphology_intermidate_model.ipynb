{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374165d6",
   "metadata": {},
   "source": [
    "# This Expermental take CNN-adrian with LSTM model\n",
    ">CNN Learn feature of ECG morphology\n",
    ">LSTM deccide the AFIB, NORM, AFLAT, OTHER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5d47c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "c:\\Users\\arjan\\Documents\\GitHub\\SEARCH_AF_detection_OsloMet_BachelorGroup\\venv\\Lib\\site-packages\\torch\\__init__.py\n",
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Dataset loader & preparation\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import random\n",
    "from collections import Counter\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "dff = pd.read_csv(\"../../../data/ptbxl_database.csv\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "print(torch.__file__)\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e02d1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LABELS = {\"NORM\", \"AFIB\", \"AFLT\"}\n",
    "\n",
    "\n",
    "norm_ids  = []\n",
    "afib_ids  = []\n",
    "aflt_ids  = []\n",
    "other_ids = []\n",
    "\n",
    "\n",
    "LABEL_MAP = {\n",
    "    \"NORM\": 0,\n",
    "    \"AFIB\": 1,\n",
    "    \"AFLT\": 2,\n",
    "    \"OTHER\": 3\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ade0d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_repeated_label(label_sets):\n",
    "    # label_sets = list of sets, one per ECG\n",
    "    all_labels = []\n",
    "    for s in label_sets:\n",
    "        all_labels.extend(list(s))\n",
    "\n",
    "    counts = Counter(all_labels)\n",
    "\n",
    "    # label appears in 2 or more recordings\n",
    "    return any(v >= 2 for v in counts.values())\n",
    "\n",
    "\n",
    "\n",
    "def extract_labels(scp_codes):\n",
    "    codes = ast.literal_eval(scp_codes)\n",
    "    return set(codes.keys()) & TARGET_LABELS\n",
    "\n",
    "def select_from_pool(pool, label, n, seed=42):\n",
    "    \"\"\"\n",
    "    Select n ECG IDs from pool[label] and REMOVE them.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    available = list(pool[label])\n",
    "\n",
    "    if len(available) < n:\n",
    "        raise ValueError(\n",
    "            f\"Not enough ECGs for label {label}. \"\n",
    "            f\"Requested {n}, available {len(available)}\"\n",
    "        )\n",
    "\n",
    "    selected = random.sample(available, n)\n",
    "\n",
    "    # remove selected from pool\n",
    "    pool[label] -= set(selected)\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6724fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FASTER for loading ECG files\n",
    "def build_ecg_index(root=\"../../../data/records500\", suffix=\"_hr\"):\n",
    "    index = {}\n",
    "    for p in Path(root).rglob(f\"*{suffix}.hea\"):\n",
    "        ecg_id = int(p.stem.replace(suffix, \"\"))\n",
    "        index[ecg_id] = str(p.with_suffix(\"\"))\n",
    "    return index\n",
    "\n",
    "ECG_INDEX = build_ecg_index()\n",
    "\n",
    "def load_ecg_fast(ecg_id):\n",
    "    record = wfdb.rdrecord(ECG_INDEX[ecg_id])\n",
    "    return record.p_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "790c4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arrays(id_label_list):\n",
    "    X, y = [], []\n",
    "    for ecg_id, label in id_label_list:\n",
    "        X.append(load_ecg_fast(ecg_id))\n",
    "        y.append(label)\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f3d881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ECG records: 21837\n",
      "Total patients: 18885\n",
      "Patients with multiple recordings: 2127\n",
      "Max recordings for one patient: 10\n",
      "Patients with multiple labels: 269\n",
      "Percentage: 1.4%\n"
     ]
    }
   ],
   "source": [
    "#Ensure if patient_id have different ECG records, all records are in the same set\n",
    "ecg_records = dff[\"ecg_id\"].count() \n",
    "print(\"Total ECG records:\", ecg_records)\n",
    "patient_ids = dff[\"patient_id\"].value_counts()\n",
    "multiple_recordings = patient_ids[patient_ids > 1]\n",
    "print(\"Total patients:\", dff[\"patient_id\"].nunique())\n",
    "print(\"Patients with multiple recordings:\", len(multiple_recordings))\n",
    "print(\"Max recordings for one patient:\", multiple_recordings.max())\n",
    "\n",
    "def get_label(scp_codes):\n",
    "    if \"AFIB\" in scp_codes:\n",
    "        return 1\n",
    "    if \"NORM\" in scp_codes:\n",
    "        return 0\n",
    "    if \"AFLT\" in scp_codes:\n",
    "        return 2\n",
    "    \n",
    "    if \"NDT\" in scp_codes:\n",
    "        return 4\n",
    "    if \"NST_\" in scp_codes:\n",
    "        return 5\n",
    "    if \"SVARR\" in scp_codes:\n",
    "        return 6\n",
    "    if \"SVTAC\" in scp_codes:\n",
    "        return 7\n",
    "    if \"PAC\" in scp_codes:\n",
    "        return 8\n",
    "    return None\n",
    "\n",
    "dff[\"label\"] = dff[\"scp_codes\"].apply(lambda x: get_label(ast.literal_eval(x)))\n",
    "label_counts_per_patient = dff.groupby(\"patient_id\")[\"label\"].nunique()\n",
    "patients_with_label_change = label_counts_per_patient[label_counts_per_patient > 1]\n",
    "\n",
    "print(\"Patients with multiple labels:\", len(patients_with_label_change))\n",
    "print(\n",
    "    \"Percentage:\",\n",
    "    f\"{round(100 * len(patients_with_label_change) / dff['patient_id'].nunique(), 1)}%\"\n",
    ")\n",
    "\n",
    "\n",
    "dff[\"target_labels\"] = dff[\"scp_codes\"].apply(extract_labels)\n",
    "dff_target = dff[dff[\"target_labels\"].apply(len) > 0]\n",
    "\n",
    "\n",
    "patient_groups = dff_target.groupby(\"patient_id\")[\"target_labels\"]\n",
    "\n",
    "\n",
    "patients_with_repeated_label = patient_groups.apply(has_repeated_label)\n",
    "# patients with more than one ECG\n",
    "patient_target_counts = dff_target[\"patient_id\"].value_counts()\n",
    "\n",
    "patients_with_multiple_target_ecgs = patient_target_counts[\n",
    "    patient_target_counts > 1\n",
    "].index\n",
    "dff_final = dff_target[\n",
    "    dff_target[\"patient_id\"].isin(patients_with_multiple_target_ecgs)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bf62d6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORM : 8329\n",
      "AFIB : 1027\n",
      "AFLT : 32\n",
      "OTHER: 2394\n",
      "TOTAL: 11782\n"
     ]
    }
   ],
   "source": [
    "dataset_root = \"../../../data/\"\n",
    "df = pd.read_csv(os.path.join(dataset_root, \"ptbxl_database.csv\"))\n",
    "for _, row in df.iterrows():\n",
    "    \n",
    "    scp_codes = ast.literal_eval(row[\"scp_codes\"])\n",
    "    label = get_label(scp_codes)\n",
    "    ecg_id = row[\"ecg_id\"]\n",
    "    p_id = row[\"patient_id\"]\n",
    "    if p_id  in dff_final[\"patient_id\"].values:\n",
    "        continue\n",
    "\n",
    "    if label is None:\n",
    "        continue\n",
    "\n",
    "\n",
    "    if label == 0:\n",
    "        norm_ids.append(ecg_id)\n",
    "\n",
    "    elif label == 1:\n",
    "        afib_ids.append(ecg_id)\n",
    "\n",
    "    elif label == 2:\n",
    "        aflt_ids.append(ecg_id)\n",
    "\n",
    "    else:\n",
    "        other_ids.append(ecg_id)\n",
    "print(\"NORM :\", len(norm_ids))\n",
    "print(\"AFIB :\", len(afib_ids))\n",
    "print(\"AFLT :\", len(aflt_ids))\n",
    "print(\"OTHER:\", len(other_ids))\n",
    "print(\"TOTAL:\", len(norm_ids) + len(afib_ids) + len(aflt_ids) + len(other_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f79aaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Learns ECG morphology:\n",
    "    QRS complex shape, amplitude, local waveform patterns\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(12, 32, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, time, leads)\n",
    "        x = x.permute(0, 2, 1)   # → (batch, leads, time)\n",
    "        x = self.cnn(x)\n",
    "        x = x.permute(0, 2, 1)   # → (batch, time, features)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "34c48ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG_CNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = CNNFeatureExtractor()   # from main_cnn\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=64,\n",
    "            hidden_size=128,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # morphology learning\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        # rhythm learning\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        # temporal pooling (VERY IMPORTANT)\n",
    "        out = out.mean(dim=1)\n",
    "\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ec897fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample_ids(ids, n, seed=42):\n",
    "    ids = np.array(ids)\n",
    "    if len(ids) < n:\n",
    "        raise ValueError(f\"Requested {n}, but only {len(ids)} available\")\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return rng.choice(ids, size=n, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ac00e088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial pool sizes:\n",
      "0 8329\n",
      "1 1027\n",
      "2 32\n",
      "3 2394\n"
     ]
    }
   ],
   "source": [
    "ecg_pool = {\n",
    "    0: set(norm_ids),\n",
    "    1: set(afib_ids),\n",
    "    2: set(aflt_ids),\n",
    "    3: set(other_ids)\n",
    "}\n",
    "\n",
    "print(\"Initial pool sizes:\")\n",
    "for k, v in ecg_pool.items():\n",
    "    print(k, len(v))\n",
    "\n",
    "TRAIN_COUNTS = {\n",
    "    0: 1500,  # NORM\n",
    "    1: 500,   # AFIB\n",
    "    \n",
    "}\n",
    "TEST_COUNTS = {\n",
    "    0: 300,\n",
    "    1: 200,\n",
    "    2: 25,   \n",
    "    3: 300\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "897a4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = []\n",
    "\n",
    "for label, n in TRAIN_COUNTS.items():\n",
    "    ids = select_from_pool(ecg_pool, label, n)\n",
    "    train_ids.extend([(eid, label) for eid in ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "09ef02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = []\n",
    "\n",
    "for label, n in TEST_COUNTS.items():\n",
    "    ids = select_from_pool(ecg_pool, label, n)\n",
    "    test_ids.extend([(eid, label) for eid in ids])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a820de",
   "metadata": {},
   "source": [
    "### Verifiction of no mixing of traingin and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "60d5092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap: 0\n"
     ]
    }
   ],
   "source": [
    "train_set = set(eid for eid, _ in train_ids)\n",
    "test_set  = set(eid for eid, _ in test_ids)\n",
    "\n",
    "print(\"Overlap:\", len(train_set & test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cfbae1",
   "metadata": {},
   "source": [
    "### Loader of ECG array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2f5bfed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arrays(id_label_list):\n",
    "    X, y = [], []\n",
    "    for ecg_id, label in id_label_list:\n",
    "        X.append(load_ecg_fast(ecg_id))\n",
    "        y.append(label)\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0c3d1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = build_arrays(train_ids)\n",
    "X_test,  y_test  = build_arrays(test_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a0de9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2ea5a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ECGDataset(X_train, y_train)\n",
    "test_dataset  = ECGDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "41de0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ECG_CNN_LSTM(num_classes=2).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aef2773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566524ab",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5a704a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 0.5438 | Train Acc: 0.724\n",
      "Epoch 02 | Loss: 0.3626 | Train Acc: 0.842\n",
      "Epoch 03 | Loss: 0.3135 | Train Acc: 0.876\n",
      "Epoch 04 | Loss: 0.2762 | Train Acc: 0.894\n",
      "Epoch 05 | Loss: 0.3181 | Train Acc: 0.874\n",
      "Epoch 06 | Loss: 0.2537 | Train Acc: 0.899\n",
      "Epoch 07 | Loss: 0.2582 | Train Acc: 0.902\n",
      "Epoch 08 | Loss: 0.2516 | Train Acc: 0.906\n",
      "Epoch 09 | Loss: 0.2338 | Train Acc: 0.909\n",
      "Epoch 10 | Loss: 0.2399 | Train Acc: 0.912\n",
      "Epoch 11 | Loss: 0.2502 | Train Acc: 0.897\n",
      "Epoch 12 | Loss: 0.2329 | Train Acc: 0.909\n",
      "Epoch 13 | Loss: 0.2597 | Train Acc: 0.901\n",
      "Epoch 14 | Loss: 0.3391 | Train Acc: 0.847\n",
      "Epoch 15 | Loss: 0.3639 | Train Acc: 0.859\n",
      "Epoch 16 | Loss: 0.2593 | Train Acc: 0.907\n",
      "Epoch 17 | Loss: 0.2573 | Train Acc: 0.905\n",
      "Epoch 18 | Loss: 0.2561 | Train Acc: 0.914\n",
      "Epoch 19 | Loss: 0.2520 | Train Acc: 0.912\n",
      "Epoch 20 | Loss: 0.3027 | Train Acc: 0.892\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    loader=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    epochs=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c1fbd2",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fef9c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, device):\n",
    "    model.eval()  \n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            logits = model(X_batch)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            y_true.extend(y_batch.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fb2e417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = test_model(model, test_loader, device)\n",
    "\n",
    "y_true_af = np.array([1 if y == 1 else 0 for y in y_true])\n",
    "y_pred_af = np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "66455967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[448 177]\n",
      " [ 51 149]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NOT_AF       0.90      0.72      0.80       625\n",
      "        AFIB       0.46      0.74      0.57       200\n",
      "\n",
      "    accuracy                           0.72       825\n",
      "   macro avg       0.68      0.73      0.68       825\n",
      "weighted avg       0.79      0.72      0.74       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "labels = [0, 1]\n",
    "#label_names = [\"NORM\", \"AFIB\", \"AFLT\", \"OTHER\"]\n",
    "\n",
    "cm = confusion_matrix(y_true_af, y_pred_af, labels=[0,1])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_true_af,\n",
    "    y_pred_af,\n",
    "    target_names=[\"NOT_AF\", \"AFIB\"]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3f4221c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_to_markdown_binary(cm):\n",
    "    \"\"\"\n",
    "    cm format:\n",
    "        [[TN, FP],\n",
    "         [FN, TP]]\n",
    "    \"\"\"\n",
    "\n",
    "    cm = np.asarray(cm, dtype=int)\n",
    "\n",
    "    TN, FP = cm[0]\n",
    "    FN, TP = cm[1]\n",
    "\n",
    "    total = cm.sum()\n",
    "    accuracy = (TP + TN) / total if total > 0 else 0.0\n",
    "\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0.0   # AF recall\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0.0   # non-AF rejection\n",
    "    fp_rate = FP / (FP + TN) if (FP + TN) > 0 else 0.0\n",
    "\n",
    "    md = []\n",
    "\n",
    "    md.append(\"## Model Evaluation Results (Binary AF Detection)\\n\")\n",
    "    md.append(\n",
    "        \"The CNN–LSTM model was evaluated as a binary atrial fibrillation detector. \"\n",
    "        \"Although the test set contained multiple rhythm types, model predictions \"\n",
    "        \"were limited to AF versus non-AF, reflecting a realistic clinical screening scenario.\\n\"\n",
    "    )\n",
    "\n",
    "    md.append(\"### Overall Performance\")\n",
    "    md.append(f\"- **Total test samples:** {total}\")\n",
    "    md.append(f\"- **Overall accuracy:** **{accuracy*100:.1f}%**\\n\")\n",
    "\n",
    "    md.append(\"### Binary Classification Metrics\")\n",
    "    md.append(f\"- **AF sensitivity (recall):** **{sensitivity*100:.1f}%**\")\n",
    "    md.append(f\"- **Non-AF specificity:** **{specificity*100:.1f}%**\")\n",
    "    md.append(f\"- **False AF alarm rate:** **{fp_rate*100:.1f}%**\\n\")\n",
    "\n",
    "    md.append(\"### Confusion Matrix Interpretation\")\n",
    "    md.append(f\"- **True Positives (AF correctly detected):** {TP}\")\n",
    "    md.append(f\"- **False Negatives (missed AF):** {FN}\")\n",
    "    md.append(f\"- **False Positives (non-AF classified as AF):** {FP}\")\n",
    "    md.append(f\"- **True Negatives (correct non-AF rejection):** {TN}\")\n",
    "\n",
    "    return \"\\n\".join(md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "747e8a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Model Evaluation Results (Binary AF Detection)\n",
       "\n",
       "The CNN–LSTM model was evaluated as a binary atrial fibrillation detector. Although the test set contained multiple rhythm types, model predictions were limited to AF versus non-AF, reflecting a realistic clinical screening scenario.\n",
       "\n",
       "### Overall Performance\n",
       "- **Total test samples:** 825\n",
       "- **Overall accuracy:** **72.4%**\n",
       "\n",
       "### Binary Classification Metrics\n",
       "- **AF sensitivity (recall):** **74.5%**\n",
       "- **Non-AF specificity:** **71.7%**\n",
       "- **False AF alarm rate:** **28.3%**\n",
       "\n",
       "### Confusion Matrix Interpretation\n",
       "- **True Positives (AF correctly detected):** 149\n",
       "- **False Negatives (missed AF):** 51\n",
       "- **False Positives (non-AF classified as AF):** 177\n",
       "- **True Negatives (correct non-AF rejection):** 448"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true_af, y_pred_af, labels=[0,1])\n",
    "\n",
    "markdown_report = confusion_matrix_to_markdown_binary(cm)\n",
    "display(Markdown(markdown_report))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
