{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd8b4b0",
   "metadata": {},
   "source": [
    "## This file contains the learning step of LSTM implementation.\n",
    "### Structure of LSTM\n",
    "- Linear Part\n",
    "- Short-term memory (hidden state)\n",
    "- Long-term memory (cell state)\n",
    "- Non-linear part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5824bb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "c:\\Users\\arjan\\Documents\\GitHub\\SEARCH_AF_detection_OsloMet_BachelorGroup\\venv\\Lib\\site-packages\\torch\\__init__.py\n",
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import random\n",
    "from collections import Counter\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "dff = pd.read_csv(\"../data/ptbxl_database.csv\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "print(torch.__file__)\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "05f31ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patients: 18885\n",
      "Patients with multiple recordings: 2127\n",
      "Max recordings for one patient: 10\n",
      "Patients with multiple labels: 269\n",
      "Percentage: 1.4%\n"
     ]
    }
   ],
   "source": [
    "#Ensure if patient_id have different ECG records, all records are in the same set\n",
    "patient_ids = dff[\"patient_id\"].value_counts()\n",
    "multiple_recordings = patient_ids[patient_ids > 1]\n",
    "print(\"Total patients:\", dff[\"patient_id\"].nunique())\n",
    "print(\"Patients with multiple recordings:\", len(multiple_recordings))\n",
    "print(\"Max recordings for one patient:\", multiple_recordings.max())\n",
    "\n",
    "def get_label(scp_codes):\n",
    "    if \"AFIB\" in scp_codes:\n",
    "        return 1\n",
    "    if \"NORM\" in scp_codes:\n",
    "        return 0\n",
    "    if \"AFLT\" in scp_codes:\n",
    "        return 2\n",
    "    \n",
    "    if \"NDT\" in scp_codes:\n",
    "        return 4\n",
    "    if \"NST_\" in scp_codes:\n",
    "        return 5\n",
    "    if \"SVARR\" in scp_codes:\n",
    "        return 6\n",
    "    if \"SVTAC\" in scp_codes:\n",
    "        return 7\n",
    "    if \"PAC\" in scp_codes:\n",
    "        return 8\n",
    "    return None\n",
    "\n",
    "dff[\"label\"] = dff[\"scp_codes\"].apply(lambda x: get_label(ast.literal_eval(x)))\n",
    "label_counts_per_patient = dff.groupby(\"patient_id\")[\"label\"].nunique()\n",
    "patients_with_label_change = label_counts_per_patient[label_counts_per_patient > 1]\n",
    "\n",
    "print(\"Patients with multiple labels:\", len(patients_with_label_change))\n",
    "print(\n",
    "    \"Percentage:\",\n",
    "    f\"{round(100 * len(patients_with_label_change) / dff['patient_id'].nunique(), 1)}%\"\n",
    ")\n",
    "TARGET_LABELS = {\"NORM\", \"AFIB\", \"AFLT\"}\n",
    "def extract_labels(scp_codes):\n",
    "    codes = ast.literal_eval(scp_codes)\n",
    "    return set(codes.keys()) & TARGET_LABELS\n",
    "\n",
    "dff[\"target_labels\"] = dff[\"scp_codes\"].apply(extract_labels)\n",
    "dff_target = dff[dff[\"target_labels\"].apply(len) > 0]\n",
    "\n",
    "\n",
    "patient_groups = dff_target.groupby(\"patient_id\")[\"target_labels\"]\n",
    "\n",
    "def has_repeated_label(label_sets):\n",
    "    # label_sets = list of sets, one per ECG\n",
    "    all_labels = []\n",
    "    for s in label_sets:\n",
    "        all_labels.extend(list(s))\n",
    "\n",
    "    counts = Counter(all_labels)\n",
    "\n",
    "    # label appears in 2 or more recordings\n",
    "    return any(v >= 2 for v in counts.values())\n",
    "patients_with_repeated_label = patient_groups.apply(has_repeated_label)\n",
    "# patients with more than one ECG\n",
    "patient_target_counts = dff_target[\"patient_id\"].value_counts()\n",
    "\n",
    "patients_with_multiple_target_ecgs = patient_target_counts[\n",
    "    patient_target_counts > 1\n",
    "].index\n",
    "dff_final = dff_target[\n",
    "    dff_target[\"patient_id\"].isin(patients_with_multiple_target_ecgs)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9dfe65f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file: ptbxl_target_labels_patients_multiple_ecgs.csv\n",
      "Rows saved: 1673\n",
      "Patients saved: 722\n"
     ]
    }
   ],
   "source": [
    "output_path = \"ptbxl_target_labels_patients_multiple_ecgs.csv\"\n",
    "\n",
    "dff_final.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Saved file:\", output_path)\n",
    "print(\"Rows saved:\", len(dff_final))\n",
    "print(\"Patients saved:\", dff_final[\"patient_id\"].nunique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2c761df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      patient_id  num_recordings\n",
      "0        8304.0               8\n",
      "1       15765.0               7\n",
      "2       17542.0               7\n",
      "3       12743.0               6\n",
      "4       13619.0               5\n",
      "..          ...             ...\n",
      "717       449.0               2\n",
      "718     21409.0               2\n",
      "719     14496.0               2\n",
      "720      8840.0               2\n",
      "721     14330.0               2\n",
      "\n",
      "[722 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "patient_record_counts = dff_final[\"patient_id\"].value_counts().reset_index()\n",
    "patient_record_counts.columns = [\"patient_id\", \"num_recordings\"]\n",
    "print(patient_record_counts.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b037ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 15765.0\n",
      "Number of recordings: 7\n",
      "       ecg_id  patient_id   age  sex  height  weight  nurse  site      device  \\\n",
      "20434   20435     15765.0  15.0    0     NaN     NaN    0.0   0.0  CS100    3   \n",
      "20448   20449     15765.0  15.0    0     NaN     NaN    0.0   0.0  CS100    3   \n",
      "20452   20453     15765.0  15.0    0     NaN     NaN    0.0   0.0  CS100    3   \n",
      "20457   20458     15765.0  15.0    0     NaN     NaN    0.0   0.0  CS100    3   \n",
      "20464   20465     15765.0  15.0    0     NaN     NaN    0.0   0.0  CS100    3   \n",
      "20480   20481     15765.0  15.0    0     NaN     NaN    0.0   0.0  CS100    3   \n",
      "20494   20495     15765.0  15.0    0     NaN     NaN    0.0   0.0  CS100    3   \n",
      "\n",
      "            recording_date  ... static_noise burst_noise electrodes_problems  \\\n",
      "20434  1999-08-06 11:25:08  ...          NaN         NaN                 NaN   \n",
      "20448  1999-08-07 13:29:28  ...          NaN         NaN                 NaN   \n",
      "20452  1999-08-08 18:07:02  ...          NaN         NaN                 NaN   \n",
      "20457  1999-08-10 12:21:08  ...          NaN         NaN                 NaN   \n",
      "20464  1999-08-13 11:08:17  ...          NaN         NaN                 NaN   \n",
      "20480  1999-08-16 10:53:18  ...          NaN         NaN                 NaN   \n",
      "20494  1999-08-22 15:33:53  ...          NaN         NaN                 NaN   \n",
      "\n",
      "      extra_beats pacemaker  strat_fold                filename_lr  \\\n",
      "20434         NaN       NaN           6  records100/20000/20435_lr   \n",
      "20448         NaN       NaN           6  records100/20000/20449_lr   \n",
      "20452         NaN       NaN           6  records100/20000/20453_lr   \n",
      "20457         NaN       NaN           6  records100/20000/20458_lr   \n",
      "20464         NaN       NaN           6  records100/20000/20465_lr   \n",
      "20480         NaN       NaN           6  records100/20000/20481_lr   \n",
      "20494         NaN       NaN           6  records100/20000/20495_lr   \n",
      "\n",
      "                     filename_hr  label target_labels  \n",
      "20434  records500/20000/20435_hr    0.0        {NORM}  \n",
      "20448  records500/20000/20449_hr    0.0        {NORM}  \n",
      "20452  records500/20000/20453_hr    0.0        {NORM}  \n",
      "20457  records500/20000/20458_hr    0.0        {NORM}  \n",
      "20464  records500/20000/20465_hr    0.0        {NORM}  \n",
      "20480  records500/20000/20481_hr    0.0        {NORM}  \n",
      "20494  records500/20000/20495_hr    0.0        {NORM}  \n",
      "\n",
      "[7 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "speicific_patient_id = 15765.0\n",
    "specific_patient_records = dff_final[dff_final[\"patient_id\"] == speicific_patient_id]\n",
    "print( \"Patient ID:\", speicific_patient_id)\n",
    "print(\"Number of recordings:\", len(specific_patient_records))\n",
    "print(specific_patient_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "44e36333",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ids  = []\n",
    "afib_ids  = []\n",
    "aflt_ids  = []\n",
    "other_ids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "829d99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"../data/\"\n",
    "df = pd.read_csv(os.path.join(dataset_root, \"ptbxl_database.csv\"))\n",
    "for _, row in df.iterrows():\n",
    "    \n",
    "    scp_codes = ast.literal_eval(row[\"scp_codes\"])\n",
    "    label = get_label(scp_codes)\n",
    "    ecg_id = row[\"ecg_id\"]\n",
    "    p_id = row[\"patient_id\"]\n",
    "    if p_id  in dff_final[\"patient_id\"].values:\n",
    "        continue\n",
    "\n",
    "    if label is None:\n",
    "        continue\n",
    "\n",
    "\n",
    "    if label == 0:\n",
    "        norm_ids.append(ecg_id)\n",
    "\n",
    "    elif label == 1:\n",
    "        afib_ids.append(ecg_id)\n",
    "\n",
    "    elif label == 2:\n",
    "        aflt_ids.append(ecg_id)\n",
    "\n",
    "    else:\n",
    "        other_ids.append(ecg_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f1bab13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORM : 8329\n",
      "AFIB : 1027\n",
      "AFLT : 32\n",
      "OTHER: 2394\n",
      "TOTAL: 11782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nbefore skip unknown labels:\\nNORM : 9491\\nAFIB : 1514\\nAFLT : 56\\nOTHER: 10776\\nTOTAL: 21837\\n'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"NORM :\", len(norm_ids))\n",
    "print(\"AFIB :\", len(afib_ids))\n",
    "print(\"AFLT :\", len(aflt_ids))\n",
    "print(\"OTHER:\", len(other_ids))\n",
    "print(\"TOTAL:\", len(norm_ids) + len(afib_ids) + len(aflt_ids) + len(other_ids))\n",
    "\n",
    "'''\n",
    "before skip unknown labels:\n",
    "NORM : 9491\n",
    "AFIB : 1514\n",
    "AFLT : 56\n",
    "OTHER: 10776\n",
    "TOTAL: 21837\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ab90a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(norm_ids).isdisjoint(afib_ids)\n",
    "assert set(norm_ids).isdisjoint(aflt_ids)\n",
    "assert set(afib_ids).isdisjoint(aflt_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba37faff",
   "metadata": {},
   "source": [
    "### Lighweight test on 100 record per each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9a539969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ids(ids, n, seed=42):\n",
    "    random.seed(seed)\n",
    "    if len(ids) <= n:\n",
    "        return ids.copy()\n",
    "    return random.sample(ids, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3e55c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled NORM : 100\n",
      "Sampled AFIB : 101\n",
      "Sampled AFLT : 32\n",
      "Sampled OTHER: 103\n",
      "Normal example IDs: [3782, 845, 10650, 9489, 8494, 4936, 3491, 2933, 17212, 1092, 1008, 3149, 8303, 8934, 21667, 897, 7555, 17109, 8394, 18398, 10787, 193, 5896, 17246, 13631, 10770, 5723, 8174, 13463, 3481, 3114, 15282, 3261, 14306, 13756, 10256, 1459, 18992, 4285, 15173, 2652, 11528, 14416, 7205, 2351, 1538, 8702, 11331, 2689, 8938, 3430, 15291, 10776, 18623, 14558, 5980, 14775, 14176, 7978, 10335, 2398, 6274, 9483, 6006, 19144, 15248, 10434, 8341, 12877, 1891, 8757, 1098, 12485, 16237, 10363, 2263, 8040, 12466, 8087, 21290, 16009, 18968, 5091, 10267, 4939, 9584, 10188, 17570, 16159, 14438, 8330, 4873, 20879, 3053, 1589, 3740, 5587, 5904, 17216, 2166] \n",
      "AFBI example IDs: [5390, 1419, 12872, 11755, 21804, 3423, 16756, 2527, 15586, 16818] \n",
      "AFLT example IDs: [449, 706, 858, 1773, 2430, 2739, 3505, 4874, 4885, 6179] \n",
      "OTHER example IDs: [3809, 907, 9749, 8593, 7936, 4665, 3502, 20169, 3069, 15103]\n"
     ]
    }
   ],
   "source": [
    "norm_sampled_ids = sample_ids(norm_ids, 100)\n",
    "afib_sampled_ids = sample_ids(afib_ids, 101)\n",
    "aflt_sampled_ids = aflt_ids.copy()\n",
    "other_sampled_ids = sample_ids(other_ids, 103)\n",
    "print(\"Sampled NORM :\", len(norm_sampled_ids))\n",
    "print(\"Sampled AFIB :\", len(afib_sampled_ids))\n",
    "print(\"Sampled AFLT :\", len(aflt_sampled_ids))\n",
    "print(\"Sampled OTHER:\", len(other_sampled_ids))\n",
    "print(\"Normal example IDs:\", norm_sampled_ids, \"\\nAFBI example IDs:\", afib_sampled_ids[:10], \"\\nAFLT example IDs:\", aflt_sampled_ids[:10], \"\\nOTHER example IDs:\", other_sampled_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d31490c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set: Counter({3: 103, 1: 101, 0: 100, 2: 32})\n"
     ]
    }
   ],
   "source": [
    "train_ids = (\n",
    "    norm_sampled_ids + afib_sampled_ids + aflt_sampled_ids + other_sampled_ids\n",
    ")\n",
    "\n",
    "\n",
    "afib_set  = set(afib_ids)\n",
    "aflt_set  = set(aflt_ids)\n",
    "norm_set  = set(norm_ids)\n",
    "other_set = set(other_ids)\n",
    "\n",
    "\n",
    "def get_class(ecg_id):\n",
    "    if ecg_id in afib_set:\n",
    "        return 1\n",
    "    if ecg_id in aflt_set:\n",
    "        return 2\n",
    "    if ecg_id in norm_set:\n",
    "        return 0\n",
    "    if ecg_id in other_set:\n",
    "        return 3\n",
    "\n",
    "label = [get_class(ecg_id) for ecg_id in train_ids]\n",
    "print(\"Class distribution in training set:\", Counter(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "80ed91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ecg(ecg_id, root=\"../data/records500\", suffix=\"_hr\"):\n",
    "    \"\"\"\n",
    "    Load PTB-XL ECG by ecg_id when files are named like:\n",
    "    03462_hr.hea / 03462_hr.dat and stored in subdirectories.\n",
    "    \"\"\"\n",
    "    target = f\"{ecg_id:05d}{suffix}.hea\"\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(root):\n",
    "        if target in filenames:\n",
    "            record_path = os.path.join(dirpath, target[:-4])  # remove .hea\n",
    "            record = wfdb.rdrecord(record_path)\n",
    "            return record.p_signal  # (5000, 12)\n",
    "\n",
    "    raise FileNotFoundError(f\"ECG ID {ecg_id} not found under {root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1948ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ecg(ecg):\n",
    "    mean = ecg.mean(axis=0)\n",
    "    std = ecg.std(axis=0) + 1e-8\n",
    "    return (ecg - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "49594d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3782 0\n",
      "845 0\n",
      "10650 0\n",
      "9489 0\n",
      "8494 0\n",
      "Unique labels: [np.int64(0), np.int64(1), np.int64(2), np.int64(3)]\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Training array\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for ecg_id in train_ids:\n",
    "    ecg = load_ecg(ecg_id)\n",
    "    ecg = normalize_ecg(ecg)\n",
    "    X.append(ecg)\n",
    "    y.append(get_class(ecg_id))\n",
    "    \n",
    "for i in range(5):\n",
    "    print(train_ids[i], y[i])\n",
    "\n",
    "\n",
    "X = np.array(X)   # (N, 5000, 12)\n",
    "y = np.array(y)   # (N,)\n",
    "print(\"Unique labels:\", sorted(set(y)))\n",
    "print(\"dtype:\", y.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fde9f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c2a269ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG_LSTM(nn.Module):\n",
    "    def __init__(self, input_size=12, hidden_size=64, num_classes=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last_out = out[:, -1, :]\n",
    "        logits = self.fc(last_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "71879ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(y)\n",
    "weights = [1.0 / counts[i] for i in range(4)]\n",
    "weights = torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad390d52",
   "metadata": {},
   "source": [
    "### Basic model LSTM with only 100 recording of each NROM, AFIB, AFLT, Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917a8f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 29.1686\n"
     ]
    }
   ],
   "source": [
    "dataset = ECGDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "model = ECG_LSTM()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "\n",
    "    \n",
    "    avg_loss = total_loss / n_batches\n",
    "    print(f\"Epoch {epoch+1} | Avg loss: {avg_loss:.4f} Loss : {total_loss:.4f}\")\n",
    "# training is DONE here\n",
    "torch.save(model.state_dict(), \"final_model.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2ddaea5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjan\\AppData\\Local\\Temp\\ipykernel_12248\\3222739296.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"final_model.pt\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "model = ECG_LSTM().to(device)\n",
    "model.load_state_dict(torch.load(\"final_model.pt\", map_location=device))\n",
    "model.eval()\n",
    "print(\"Model device:\", next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9a0df0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(ecg):\n",
    "    mean = ecg.mean(axis=0)\n",
    "    std = ecg.std(axis=0) + 1e-8\n",
    "    return (ecg - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cc78fe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763 is NOT in norm_set\n"
     ]
    }
   ],
   "source": [
    "  # example ECG ID\n",
    "ecg_id = 763\n",
    "\n",
    "if ecg_id not in norm_set:\n",
    "    print(f\"{ecg_id} is NOT in norm_set\")\n",
    "else:\n",
    "    print(f\"{ecg_id} IS in norm_set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5335f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ecg = load_ecg(ecg_id)\n",
    "ecg = normalize(ecg)\n",
    "\n",
    "X = torch.tensor(ecg, dtype=torch.float32)\n",
    "X = X.unsqueeze(0)   # (1, 5000, 12)\n",
    "X = X.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "404bfb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(X)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    pred = torch.argmax(probs, dim=1).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b9745cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rhythm: OTHER\n",
      "Class probabilities: [[0.26019028 0.22515209 0.24621683 0.2684408 ]]\n"
     ]
    }
   ],
   "source": [
    "label_map = {\n",
    "    0: \"NORM\",\n",
    "    1: \"AFIB\",\n",
    "    2: \"AFLT\",\n",
    "    3: \"OTHER\"\n",
    "}\n",
    "\n",
    "print(\"Predicted rhythm:\", label_map[pred])\n",
    "print(\"Class probabilities:\", probs.cpu().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
