{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd8b4b0",
   "metadata": {},
   "source": [
    "## This file contains the learning step of LSTM implementation.\n",
    "### Structure of LSTM\n",
    "- Linear Part\n",
    "- Short-term memory (hidden state)\n",
    "- Long-term memory (cell state)\n",
    "- Non-linear part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5824bb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "c:\\Users\\arjan\\Documents\\GitHub\\SEARCH_AF_detection_OsloMet_BachelorGroup\\venv\\Lib\\site-packages\\torch\\__init__.py\n",
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import random\n",
    "from collections import Counter\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "dff = pd.read_csv(\"../data/ptbxl_database.csv\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "print(torch.__file__)\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f31ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patients: 18885\n",
      "Patients with multiple recordings: 2127\n",
      "Max recordings for one patient: 10\n",
      "Total patients: 18885\n",
      "Patients with multiple labels: 269\n",
      "Percentage: 1.4%\n"
     ]
    }
   ],
   "source": [
    "#Ensure if patient_id have different ECG records, all records are in the same set\n",
    "patient_ids = dff[\"patient_id\"].value_counts()\n",
    "multiple_recordings = patient_ids[patient_ids > 1]\n",
    "print(\"Total patients:\", df[\"patient_id\"].nunique())\n",
    "print(\"Patients with multiple recordings:\", len(multiple_recordings))\n",
    "print(\"Max recordings for one patient:\", multiple_recordings.max())\n",
    "\n",
    "def get_label(scp_codes):\n",
    "    if \"AFIB\" in scp_codes:\n",
    "        return 1\n",
    "    if \"NORM\" in scp_codes:\n",
    "        return 0\n",
    "    if \"AFLT\" in scp_codes:\n",
    "        return 2\n",
    "    \n",
    "    if \"NDT\" in scp_codes:\n",
    "        return 4\n",
    "    if \"NST_\" in scp_codes:\n",
    "        return 5\n",
    "    if \"SVARR\" in scp_codes:\n",
    "        return 6\n",
    "    if \"SVTAC\" in scp_codes:\n",
    "        return 7\n",
    "    if \"PAC\" in scp_codes:\n",
    "        return 8\n",
    "    return None\n",
    "\n",
    "dff[\"label\"] = dff[\"scp_codes\"].apply(lambda x: get_label(ast.literal_eval(x)))\n",
    "label_counts_per_patient = dff.groupby(\"patient_id\")[\"label\"].nunique()\n",
    "patients_with_label_change = label_counts_per_patient[label_counts_per_patient > 1]\n",
    "print(\"Total patients:\", df[\"patient_id\"].nunique())\n",
    "print(\"Patients with multiple labels:\", len(patients_with_label_change))\n",
    "print(\n",
    "    \"Percentage:\",\n",
    "    str(round(100 * len(patients_with_label_change) / dff[\"patient_id\"].nunique(), 1)) +\"%\"\n",
    ")\n",
    "TARGET_LABELS = {\"NORM\", \"AFIB\", \"AFLT\"}\n",
    "def extract_labels(scp_codes):\n",
    "    codes = ast.literal_eval(scp_codes)\n",
    "    return set(codes.keys() & TARGET_LABELS)\n",
    "\n",
    "dff[\"labels\"] = dff[\"scp_codes\"].apply(extract_labels)\n",
    "patient_groups = dff.groupby(\"patient_id\")[\"labels\"]\n",
    "\n",
    "def has_repeated_label(label_sets):\n",
    "    # label_sets = list of sets, one per ECG\n",
    "    all_labels = []\n",
    "    for s in label_sets:\n",
    "        all_labels.extend(list(s))\n",
    "\n",
    "    counts = Counter(all_labels)\n",
    "\n",
    "    # label appears in 2 or more recordings\n",
    "    return any(v >= 2 for v in counts.values())\n",
    "patients_with_repeated_label = patient_groups.apply(has_repeated_label)\n",
    "# patients with more than one ECG\n",
    "multi_record_patients = dff[\"patient_id\"].value_counts()\n",
    "multi_record_patients = multi_record_patients[multi_record_patients > 1].index\n",
    "\n",
    "# final selection\n",
    "selected_patients = patients_with_repeated_label[\n",
    "    patients_with_repeated_label.index.isin(multi_record_patients)\n",
    "]\n",
    "\n",
    "selected_patients = selected_patients[selected_patients]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9dfe65f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients with >1 ECG: 2127\n",
      "Patients with repeated label across recordings: 1957\n",
      "Percentage: 92.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id</th>\n",
       "      <th>scp_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6317</th>\n",
       "      <td>6318</td>\n",
       "      <td>{'IMI': 50.0, 'IRBBB': 100.0, 'LAFB': 100.0, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6324</th>\n",
       "      <td>6325</td>\n",
       "      <td>{'AMI': 50.0, 'IRBBB': 100.0, 'LAFB': 100.0, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id                                          scp_codes\n",
       "6317    6318  {'IMI': 50.0, 'IRBBB': 100.0, 'LAFB': 100.0, '...\n",
       "6324    6325  {'AMI': 50.0, 'IRBBB': 100.0, 'LAFB': 100.0, '..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Patients with >1 ECG:\", len(multi_record_patients))\n",
    "print(\"Patients with repeated label across recordings:\", len(selected_patients))\n",
    "\n",
    "print(\n",
    "    \"Percentage:\",\n",
    "    str(round(\n",
    "        100 * len(selected_patients) / len(multi_record_patients), 1\n",
    "    )) + \"%\"\n",
    ")\n",
    "example_patient = selected_patients.index[2]\n",
    "\n",
    "dff[dff[\"patient_id\"] == example_patient][\n",
    "    [\"ecg_id\", \"scp_codes\"]\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e36333",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ids  = []\n",
    "afib_ids  = []\n",
    "aflt_ids  = []\n",
    "other_ids = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"../data/\"\n",
    "df = pd.read_csv(os.path.join(dataset_root, \"ptbxl_database.csv\"))\n",
    "for _, row in df.iterrows():\n",
    "    \n",
    "    scp_codes = ast.literal_eval(row[\"scp_codes\"])\n",
    "    label = get_label(scp_codes)\n",
    "    ecg_id = row[\"ecg_id\"]\n",
    "\n",
    "    if label is None:\n",
    "        continue\n",
    "\n",
    "    if label == 0:\n",
    "        norm_ids.append(ecg_id)\n",
    "\n",
    "    elif label == 1:\n",
    "        afib_ids.append(ecg_id)\n",
    "\n",
    "    elif label == 2:\n",
    "        aflt_ids.append(ecg_id)\n",
    "\n",
    "    else:\n",
    "        other_ids.append(ecg_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1bab13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORM : 9491\n",
      "AFIB : 1514\n",
      "AFLT : 56\n",
      "OTHER: 2442\n",
      "TOTAL: 13503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nbefore skip unknown labels:\\nNORM : 9491\\nAFIB : 1514\\nAFLT : 56\\nOTHER: 10776\\nTOTAL: 21837\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"NORM :\", len(norm_ids))\n",
    "print(\"AFIB :\", len(afib_ids))\n",
    "print(\"AFLT :\", len(aflt_ids))\n",
    "print(\"OTHER:\", len(other_ids))\n",
    "print(\"TOTAL:\", len(norm_ids) + len(afib_ids) + len(aflt_ids) + len(other_ids))\n",
    "\n",
    "'''\n",
    "before skip unknown labels:\n",
    "NORM : 9491\n",
    "AFIB : 1514\n",
    "AFLT : 56\n",
    "OTHER: 10776\n",
    "TOTAL: 21837\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab90a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(norm_ids).isdisjoint(afib_ids)\n",
    "assert set(norm_ids).isdisjoint(aflt_ids)\n",
    "assert set(afib_ids).isdisjoint(aflt_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba37faff",
   "metadata": {},
   "source": [
    "### Lighweight test on 100 record per each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a539969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ids(ids, n, seed=42):\n",
    "    random.seed(seed)\n",
    "    if len(ids) <= n:\n",
    "        return ids.copy()\n",
    "    return random.sample(ids, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e55c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled NORM : 100\n",
      "Sampled AFIB : 101\n",
      "Sampled AFLT : 56\n",
      "Sampled OTHER: 103\n",
      "Normal example IDs: [3462, 772, 9521, 8318, 7583, 4376, 3149, 20114, 2678, 15049, 979, 916, 2890, 7395, 7928, 18367, 809, 20892, 6597, 20094, 14940, 7465, 16155, 9667, 151, 5220, 15083, 11996, 9646, 5013, 7258, 11861, 3140, 2855, 13551, 2973, 12698, 12123, 9120, 1326, 16542, 19724, 3887, 13506, 2424, 20411, 10163, 12789, 21755, 6348, 2168, 1389, 7754, 10020, 2449, 7932, 3102, 13560, 9658, 16310, 12947, 5344, 13149, 12541, 6999, 9229, 2224, 5622, 19627, 8313, 5380, 16648, 13540, 9339, 20666, 7430, 11381, 1718, 7793, 989, 11000, 14231, 9258, 2059, 7070, 21241, 10974, 7126, 18125, 14067, 16516, 4504, 9132, 4378, 8397, 20897, 19844, 9057, 15360, 14179] \n",
      "AFBI example IDs: [19774, 4451, 1026, 9241, 8276, 7492, 5286, 21779, 4154, 20488] \n",
      "AFLT example IDs: [18, 20, 23, 34, 336, 347, 449, 706, 858, 1173] \n",
      "OTHER example IDs: [3739, 880, 9570, 8423, 7755, 4548, 3464, 19767, 3028, 21606]\n"
     ]
    }
   ],
   "source": [
    "norm_sampled_ids = sample_ids(norm_ids, 100)\n",
    "afib_sampled_ids = sample_ids(afib_ids, 101)\n",
    "aflt_sampled_ids = aflt_ids.copy()\n",
    "other_sampled_ids = sample_ids(other_ids, 103)\n",
    "print(\"Sampled NORM :\", len(norm_sampled_ids))\n",
    "print(\"Sampled AFIB :\", len(afib_sampled_ids))\n",
    "print(\"Sampled AFLT :\", len(aflt_sampled_ids))\n",
    "print(\"Sampled OTHER:\", len(other_sampled_ids))\n",
    "print(\"Normal example IDs:\", norm_sampled_ids, \"\\nAFBI example IDs:\", afib_sampled_ids[:10], \"\\nAFLT example IDs:\", aflt_sampled_ids[:10], \"\\nOTHER example IDs:\", other_sampled_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31490c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set: Counter({3: 103, 1: 101, 0: 100, 2: 56})\n"
     ]
    }
   ],
   "source": [
    "train_ids = (\n",
    "    norm_sampled_ids + afib_sampled_ids + aflt_sampled_ids + other_sampled_ids\n",
    ")\n",
    "\n",
    "\n",
    "afib_set  = set(afib_ids)\n",
    "aflt_set  = set(aflt_ids)\n",
    "norm_set  = set(norm_ids)\n",
    "other_set = set(other_ids)\n",
    "\n",
    "\n",
    "def get_class(ecg_id):\n",
    "    if ecg_id in afib_set:\n",
    "        return 1\n",
    "    if ecg_id in aflt_set:\n",
    "        return 2\n",
    "    if ecg_id in norm_set:\n",
    "        return 0\n",
    "    if ecg_id in other_set:\n",
    "        return 3\n",
    "\n",
    "label = [get_class(ecg_id) for ecg_id in train_ids]\n",
    "print(\"Class distribution in training set:\", Counter(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ed91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ecg(ecg_id, root=\"../data/records500\", suffix=\"_hr\"):\n",
    "    \"\"\"\n",
    "    Load PTB-XL ECG by ecg_id when files are named like:\n",
    "    03462_hr.hea / 03462_hr.dat and stored in subdirectories.\n",
    "    \"\"\"\n",
    "    target = f\"{ecg_id:05d}{suffix}.hea\"\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(root):\n",
    "        if target in filenames:\n",
    "            record_path = os.path.join(dirpath, target[:-4])  # remove .hea\n",
    "            record = wfdb.rdrecord(record_path)\n",
    "            return record.p_signal  # (5000, 12)\n",
    "\n",
    "    raise FileNotFoundError(f\"ECG ID {ecg_id} not found under {root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49594d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training array\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for ecg_id in train_ids:\n",
    "    ecg = load_ecg(ecg_id)\n",
    "    X.append(ecg)\n",
    "    y.append(get_class(ecg_id))\n",
    "\n",
    "X = np.array(X)   # (N, 5000, 12)\n",
    "y = np.array(y)   # (N,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fde9f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2a269ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG_LSTM(nn.Module):\n",
    "    def __init__(self, input_size=12, hidden_size=64, num_classes=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last_out = out[:, -1, :]\n",
    "        logits = self.fc(last_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71879ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(y)\n",
    "weights = [1.0 / counts[i] for i in range(4)]\n",
    "weights = torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "917a8f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 32.0717\n",
      "Epoch 2 | Loss: 31.8723\n",
      "Epoch 3 | Loss: 31.8126\n",
      "Epoch 4 | Loss: 31.7534\n",
      "Epoch 5 | Loss: 31.6539\n",
      "Epoch 6 | Loss: 31.5467\n",
      "Epoch 7 | Loss: 31.3019\n",
      "Epoch 8 | Loss: 31.3382\n",
      "Epoch 9 | Loss: 31.3360\n",
      "Epoch 10 | Loss: 31.1882\n",
      "Epoch 11 | Loss: 31.0542\n",
      "Epoch 12 | Loss: 30.9654\n",
      "Epoch 13 | Loss: 30.8390\n",
      "Epoch 14 | Loss: 30.7120\n",
      "Epoch 15 | Loss: 30.7056\n",
      "Epoch 16 | Loss: 30.4555\n",
      "Epoch 17 | Loss: 30.3701\n",
      "Epoch 18 | Loss: 29.8953\n",
      "Epoch 19 | Loss: 29.9741\n",
      "Epoch 20 | Loss: 29.9096\n"
     ]
    }
   ],
   "source": [
    "dataset = ECGDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "model = ECG_LSTM()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f}\")\n",
    "# training is DONE here\n",
    "torch.save(model.state_dict(), \"final_model.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ddaea5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjan\\AppData\\Local\\Temp\\ipykernel_12248\\3222739296.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"final_model.pt\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "model = ECG_LSTM().to(device)\n",
    "model.load_state_dict(torch.load(\"final_model.pt\", map_location=device))\n",
    "model.eval()\n",
    "print(\"Model device:\", next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a0df0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(ecg):\n",
    "    mean = ecg.mean(axis=0)\n",
    "    std = ecg.std(axis=0) + 1e-8\n",
    "    return (ecg - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc78fe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636 is NOT in norm_set\n"
     ]
    }
   ],
   "source": [
    "  # example ECG ID\n",
    "ecg_id = 636\n",
    "\n",
    "if ecg_id not in norm_set:\n",
    "    print(f\"{ecg_id} is NOT in norm_set\")\n",
    "else:\n",
    "    print(f\"{ecg_id} IS in norm_set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5335f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ecg = load_ecg(ecg_id)\n",
    "ecg = normalize(ecg)\n",
    "\n",
    "X = torch.tensor(ecg, dtype=torch.float32)\n",
    "X = X.unsqueeze(0)   # (1, 5000, 12)\n",
    "X = X.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "404bfb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(X)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    pred = torch.argmax(probs, dim=1).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9745cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rhythm: AFLT\n",
      "Class probabilities: [[0.37144315 0.0950818  0.4175679  0.11590715]]\n"
     ]
    }
   ],
   "source": [
    "label_map = {\n",
    "    0: \"NORM\",\n",
    "    1: \"AFIB\",\n",
    "    2: \"AFLT\",\n",
    "    3: \"OTHER\"\n",
    "}\n",
    "\n",
    "print(\"Predicted rhythm:\", label_map[pred])\n",
    "print(\"Class probabilities:\", probs.cpu().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
